{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a473efc-098c-46ad-b282-93c109d52378",
   "metadata": {},
   "source": [
    "# LangGraph Demo\n",
    "## 3 Agents üëá\n",
    "* ReAct Agent built with LangGraph + Claude + Taviily Web Search\n",
    "* Agentic Workflow that has access to Wikipedia Search & Summarization\n",
    "* Multi-Agent System that has access to [TOOL_NAME]\n",
    "![Screenshot 2025-07-12 at 3.24.50‚ÄØPM.png](attachment:c9c64c56-ad8b-48a8-ad26-a59d424faa26.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a425b6c-b866-4c03-98d4-103bfe0babef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import environment file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# text structure\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Union, Callable\n",
    "from pydantic import BaseModel, Field\n",
    "from urllib.parse import quote\n",
    "\n",
    "# datetime\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "# LangGraph graph def\n",
    "from langgraph.graph import MessagesState, START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# Messages\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Claude & OpenAI integration\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# creating ReAct agents with Supervisor architecture\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Define Tavily Search + Wiki Tools\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools.tavily_search.tool import TavilySearchResults\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# jupyter finessing\n",
    "from IPython.display import Image, display, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# gradio\n",
    "import gradio as gr\n",
    "\n",
    "# needed for concurrent evals in notebook envs\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6120a-8a48-4c83-b644-53c10bbb412c",
   "metadata": {},
   "source": [
    "# ReAct Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07029e-141c-45da-aeff-a94520723801",
   "metadata": {},
   "source": [
    "## Model Initialization üéà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1215b67c-c2b6-4cdc-8ade-cd28d36170f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "if not anthropic_api_key:\n",
    "    print(\"ANTHROPIC_API_KEY environment variable not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f053e8-ccc9-4201-9f02-4f7a7cf69e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'claude-sonnet-4-20250514'\n",
    "# 'claude-4-sonnet-20250514'\n",
    "# 'claude-opus-4-20250514'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca12520-4548-4c9c-aef0-41182c8b42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ChatAnthropic(\n",
    "    model_name=MODEL,\n",
    "    temperature=1,\n",
    "    max_tokens=2000,\n",
    "    \n",
    "    # Enable thinking with budget_tokens as required by API  \n",
    "    thinking={\"type\": \"enabled\", \"budget_tokens\": 1024},\n",
    "    \n",
    "    # Enable interleaved thinking for better tool use and reasoning\n",
    "    extra_headers={\n",
    "        \"anthropic-beta\": \"interleaved-thinking-2025-05-14\"\n",
    "    },\n",
    "    \n",
    "    # Enable keep-alive as recommended by Anthropic\n",
    "    timeout=300.0,  # 5 minute timeout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f2c1e-a3e1-4a88-81b3-6a87ffa8627d",
   "metadata": {},
   "source": [
    "## Define Tools ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f57df-4a27-43ae-9b91-161ac109fc6b",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Tavily Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb60771b-a235-45ef-99fe-c1eb229d8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "if not tavily_api_key:\n",
    "    print(\"TAVILY_API_KEY environment variable not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabfcef4-9f0f-491e-a98c-c74a434e8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tavily_search_tool(tavily_api_key):\n",
    "    \"\"\"\n",
    "    Create the Tavily search tool with token management.\n",
    "    \n",
    "    Args:\n",
    "        tavily_api_key: API key for Tavily\n",
    "    Returns:\n",
    "        Configured search tool or None if failed\n",
    "\n",
    "     Use this tool when:\n",
    "    - User asks questions that require current info\n",
    "    \"\"\"\n",
    "    try:\n",
    "        def tavily_search(query, *args, **kwargs):\n",
    "            \n",
    "            try:\n",
    "                print(f\"Making Tavily API call for: {query[:50]}...\")\n",
    "                results = TavilySearchResults(api_key=tavily_api_key,\n",
    "                                             # k=1,\n",
    "                                             include_raw_content=False,\n",
    "                                             include_images=False,\n",
    "                                             include_answer=True,\n",
    "                                             max_results=1,\n",
    "                                             search_depth=\"basic\")(query, *args, **kwargs)\n",
    "                \n",
    "                return results\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in Tavily search: {e}\")\n",
    "                \n",
    "                return error_result\n",
    "\n",
    "        search_tool = Tool(\n",
    "            name=\"tavily_search_results\",\n",
    "            func=tavily_search,\n",
    "            description=\n",
    "            \"Search the web for current information. Useful for questions about current events or trending topics.\"\n",
    "        )\n",
    "\n",
    "        print(\"Successfully initialized Tavily Search with token management\")\n",
    "        return search_tool\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize Tavily Search: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6615f1-cb92-4224-bb1c-9b41005fddad",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ DateTime Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b9075fe-e531-4eb3-8835-eca0e0ddc9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"\n",
    "    Get the current date and time in a user-friendly format.\n",
    "    \n",
    "    Returns:\n",
    "        str: Current date and time in format \"Friday, May 23, 2025 at 12:45 PM EST\"\n",
    "    \n",
    "    Use this tool when:\n",
    "    - User asks about current date, time, or \"today\"\n",
    "    - User mentions \"this week\", \"next week\", \"this month\", etc.\n",
    "    - User asks about weather forecasts or current events\n",
    "    - Any time-sensitive queries that need current context\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get current datetime in UTC\n",
    "        now_utc = datetime.now(timezone.utc)\n",
    "        \n",
    "        # Format for user display\n",
    "        formatted_date = now_utc.strftime(\"%A, %B %d, %Y at %I:%M %p UTC\")\n",
    "        \n",
    "        return f\"Current date and time: {formatted_date}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error getting current datetime: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91f551-5be8-4c7a-9d5c-7f8060d6c4f1",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Wiki Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf7849c-ba19-4491-b887-ef8a1161d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wikipedia_tool():\n",
    "    \"\"\"\n",
    "    Create a Wikipedia search tool.\n",
    "\n",
    "    Returns:\n",
    "        Configured Wikipedia tool or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        api_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=3000)\n",
    "\n",
    "        # Wrap the Wikipedia run to provide error handling, token management, and caching\n",
    "        def wiki_query_with_handling(query):\n",
    "            # Input validation\n",
    "            if not query or not isinstance(query, str):\n",
    "                return \"Invalid query: Please provide a valid search term.\"\n",
    "            \n",
    "            # Sanitize query - remove potentially problematic characters\n",
    "            query = query.strip()\n",
    "            if len(query) > 300:  # Align with WIKIPEDIA_MAX_QUERY_LENGTH\n",
    "                query = query[:300]\n",
    "            \n",
    "            try:\n",
    "                print(f\"Making Wikipedia API call for: {query[:50]}...\")\n",
    "                result = api_wrapper.run(query)\n",
    "\n",
    "                # Limit result size to avoid token issues\n",
    "                if len(result) > 4000:\n",
    "                    result = result[:4000] + \"... [content truncated for brevity]\"\n",
    "\n",
    "                # Add Wikipedia source URL with proper encoding\n",
    "                wiki_title = quote(query.replace(' ', '_'), safe='')\n",
    "                wiki_url = f\"https://en.wikipedia.org/wiki/{wiki_title}\"\n",
    "                result += f\"\\n\\nSources:\\n{wiki_url}\"\n",
    "\n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_result = \"Wikipedia search encountered an error. Please try a different query or check your connection.\"\n",
    "                print(f\"Error in Wikipedia search: {e}\")\n",
    "                \n",
    "                return error_result\n",
    "\n",
    "        # Create the tool with our wrapped function\n",
    "        wiki_tool = Tool(\n",
    "            name=\"wikipedia_query_run\",\n",
    "            func=wiki_query_with_handling,\n",
    "            description=\"\"\"Searches Wikipedia for information about a given topic. \n",
    "            Use for historical, scientific, or general knowledge queries.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        print(\"Successfully initialized Wikipedia tool\")\n",
    "        return wiki_tool\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize Wikipedia tool: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849c946-aef6-49a7-b65e-5250ebe7994a",
   "metadata": {},
   "source": [
    "### Prompt Template üìù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad8ab702-6902-4134-8850-04809eb068de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt():\n",
    "    \"\"\"\n",
    "    Returns an enhanced prompt for the ReACT agent that coordinates between multiple tools.\n",
    "    Include special instructions for handling content.\n",
    "    \"\"\"\n",
    "    return \"\"\"\n",
    "    You are an expert AI assistant with access to powerful tools for research and information gathering.\n",
    "\n",
    "    CAPABILITIES:\n",
    "    - Web search via Tavily (for current events, news, real-time information)\n",
    "    - Wikipedia search (for encyclopedic knowledge, historical facts, established concepts)\n",
    "    - Current date/time information\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. **Tool Selection Strategy**:\n",
    "       - Use Tavily search for: recent events, current facts, market data, news, trending topics\n",
    "       - Use Wikipedia for: historical information, established concepts, biographical data, scientific facts\n",
    "       - Get current datetime before searching when queries involve time-sensitive information\n",
    "    \n",
    "    2. **Response Guidelines**:\n",
    "       - Always provide direct, helpful answers based on your research\n",
    "       - Synthesize information from multiple sources when appropriate\n",
    "       - If you need to search for information, explain briefly what you're looking for\n",
    "       - Cite sources when presenting factual claims from your searches\n",
    "       - Be concise but thorough in your explanations\n",
    "    \n",
    "    3. **Search Strategy**:\n",
    "       - For time-sensitive queries (weather, recent events), always get current date first\n",
    "       - Use multiple searches if needed to provide comprehensive answers\n",
    "       - Prefer authoritative sources and recent information\n",
    "    \n",
    "    4. **Communication Style**:\n",
    "       - Be helpful, accurate, and conversational\n",
    "       - Acknowledge when you're searching for information\n",
    "       - Present information clearly and organize complex topics logically\n",
    "    \n",
    "    Current date context will be provided when you use the datetime tool.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a157d08f-b644-440f-b024-cecc291b3c99",
   "metadata": {},
   "source": [
    "## Initialize Tools ‚úÖ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2738ee8-0b42-467e-a9fe-ad592d9be155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized Tavily Search with token management\n",
      "‚úÖ Tavily search tool initialized\n",
      "Successfully initialized Wikipedia tool\n",
      "‚úÖ Wikipedia tool initialized\n",
      "‚úÖ DateTime tool initialized\n",
      "\n",
      "üéØ Agent created with 3 tools:\n",
      "   - tavily_search_results\n",
      "   - wikipedia_query_run\n",
      "   - get_current_datetime\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize the tools properly by calling the factory functions\n",
    "def initialize_tools():\n",
    "    \"\"\"Initialize all tools and return them as a list\"\"\"\n",
    "    tools = []\n",
    "    \n",
    "    # Initialize Tavily search tool\n",
    "    if tavily_api_key:\n",
    "        tavily_tool = create_tavily_search_tool(tavily_api_key)\n",
    "        if tavily_tool:\n",
    "            tools.append(tavily_tool)\n",
    "            print(\"‚úÖ Tavily search tool initialized\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to initialize Tavily search tool\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Tavily API key not found, skipping Tavily tool\")\n",
    "    \n",
    "    # Initialize Wikipedia tool\n",
    "    wiki_tool = create_wikipedia_tool()\n",
    "    if wiki_tool:\n",
    "        tools.append(wiki_tool)\n",
    "        print(\"‚úÖ Wikipedia tool initialized\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to initialize Wikipedia tool\")\n",
    "    \n",
    "    # Add datetime tool\n",
    "    tools.append(get_current_datetime)\n",
    "    print(\"‚úÖ DateTime tool initialized\")\n",
    "    \n",
    "    return tools\n",
    "\n",
    "# 3. Initialize tools\n",
    "available_tools = initialize_tools()\n",
    "\n",
    "print(f\"\\nüéØ Agent created with {len(available_tools)} tools:\")\n",
    "for tool in available_tools:\n",
    "    if hasattr(tool, 'name'):\n",
    "        print(f\"   - {tool.name}\")\n",
    "    else:\n",
    "        print(f\"   - {tool}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d090d-42bd-4b64-adce-6f3b3197604f",
   "metadata": {},
   "source": [
    "## Create First ReAct Agent ü§ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0677114b-9935-4b6e-9ada-69a436ecbfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_one = create_react_agent(\n",
    "    model=claude,\n",
    "    tools=available_tools,\n",
    "    name=\"expert_sme\",\n",
    "    prompt=get_prompt(),\n",
    "\n",
    "    # add Memory\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913f7e37-65d5-4376-94a5-5f438e25ed38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(agent_one.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7406a6-0c4c-41f9-b6be-01c005637b24",
   "metadata": {},
   "source": [
    "## ‚ùìQuestions with Multiple Tool Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "599771ca-d483-42d5-9ff1-4acb1430c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_agent_trace(query):\n",
    "    \"\"\"\n",
    "    Break down user / agent interaction trace into streams for surface-level observability.\n",
    "    \"\"\"\n",
    "    _thread_counter = 0\n",
    "    \n",
    "    # Get tracer (ensure Phoenix is set up first)\n",
    "    # tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    # Auto-increment thread_id\n",
    "    _thread_counter += 1\n",
    "    thread_id = f\"thread_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{_thread_counter}\"\n",
    "\n",
    "    # Define config with thread_id\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id\n",
    "        },\n",
    "        \"recursion_limit\": 50,\n",
    "        \"max_execution_time\": 300,  # 5 min timeout\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nü§î USER QUERY: {query}\")\n",
    "    print(f\"üîó Thread ID: {thread_id}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    step_counter = 1\n",
    "    reasoning_parts = []\n",
    "    \n",
    "    for msg, metadata in agent_one.stream(\n",
    "        {\"messages\": [HumanMessage(content=query)]}, \n",
    "        config, \n",
    "        stream_mode=\"messages\"\n",
    "    ):\n",
    "        # safely extract message type\n",
    "        msg_type = getattr(msg, 'type', None) \n",
    "        \n",
    "        # Handle HumanMessage (user input)\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            continue  # Skip user messages in trace\n",
    "        \n",
    "        # Handle AIMessage (assistant responses)\n",
    "        elif hasattr(msg, 'content') and msg.content:\n",
    "            \n",
    "            if isinstance(msg.content, list):\n",
    "                for block in msg.content:\n",
    "                    if isinstance(block, dict):\n",
    "                        block_type = block.get('type', '')\n",
    "                        \n",
    "                        # Reasoning/Thinking\n",
    "                        if block_type == 'thinking':\n",
    "                            reasoning_parts.append(block.get('thinking', ''))\n",
    "                        \n",
    "                        # Agent speech/explanation\n",
    "                        elif block_type == 'text':\n",
    "                            # Show accumulated reasoning first\n",
    "                            if reasoning_parts:\n",
    "                                reasoning_text = ''.join(reasoning_parts).strip()\n",
    "                                if reasoning_text:\n",
    "                                    print(f\"\\nüß† STEP {step_counter} - AGENT REASONING:\")\n",
    "                                    print(f\"   {reasoning_text}\")\n",
    "                                    reasoning_parts = []\n",
    "                                    step_counter += 1\n",
    "                            \n",
    "                            text_content = block.get('text', '').strip()\n",
    "                            if text_content:\n",
    "                                print(f\"\\nü§ñ ASSISTANT RESPONSE:\")\n",
    "                                print(f\"   {text_content}\")\n",
    "                        \n",
    "                        # Tool usage\n",
    "                        elif block_type == 'tool_use':\n",
    "                            tool_name = block.get('name', '')\n",
    "                            tool_input = block.get('input', {})\n",
    "                            \n",
    "                            print(f\"\\nüîß TOOL CALL:\")\n",
    "                            print(f\"   Using: {tool_name}\")\n",
    "                            if tool_input:\n",
    "                                print(f\"   Parameters: {tool_input}\")\n",
    "            \n",
    "            # Handle direct string responses\n",
    "            elif isinstance(msg.content, str):\n",
    "                content = msg.content.strip()\n",
    "                if content:\n",
    "                    print(f\"\\nü§ñ ASSISTANT:\")\n",
    "                    print(f\"   {content}\")\n",
    "        \n",
    "        # Handle ToolMessage (tool results)\n",
    "        elif msg_type == 'tool':\n",
    "            print(f\"\\nüìä TOOL RESULT:\")\n",
    "            content = getattr(msg, 'content', '')\n",
    "            # Truncate long tool results for readability\n",
    "            if len(content) > 300:\n",
    "                print(f\"   {content[:300]}...\")\n",
    "            else:\n",
    "                print(f\"   {content}\")\n",
    "    \n",
    "    # Show any final reasoning\n",
    "    if reasoning_parts:\n",
    "        reasoning_text = ''.join(reasoning_parts).strip()\n",
    "        if reasoning_text:\n",
    "            print(f\"\\nüß† FINAL REASONING:\")\n",
    "            print(f\"   {reasoning_text}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ QUERY COMPLETED\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345a1ae2-1ffa-4f74-9e1f-239fb09323dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"what's the weather like in Queens today?\", \n",
    "    \"Who was the King of the Ancient Greek Gods?\",\n",
    "    \"What's the best method to evaluate an LLM?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8773a7fd-55f3-4b27-9ead-ca1ca314f4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "ü§î USER QUERY: what's the weather like in Queens today?\n",
      "üîó Thread ID: thread_20250910_130100_1\n",
      "================================================================================\n",
      "\n",
      "üß† STEP 1 - AGENT REASONING:\n",
      "   The user is asking about the weather in Queens today. This is a current, time-sensitive query, so I should:\n",
      "\n",
      "1. First get the current date/time to know what \"today\" means\n",
      "2. Then search for current weather information in Queens\n",
      "\n",
      "Let me start with getting the current datetime.\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   I'll help you get the current\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   weather information for Queens. Let me first\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   check what today's date is,\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   then search for the current weather conditions.\n",
      "\n",
      "üîß TOOL CALL:\n",
      "   Using: get_current_datetime\n",
      "\n",
      "ü§ñ ASSISTANT:\n",
      "   Current date and time: Wednesday, September 10, 2025 at 05:01 PM UTC\n",
      "\n",
      "üîß TOOL CALL:\n",
      "   Using: tavily_search_results\n",
      "Making Tavily API call for: current weather Queens New York today September 10...\n",
      "\n",
      "ü§ñ ASSISTANT:\n",
      "   [{\"title\": \"Weather in Queens, New York\", \"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'Queens Village', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7267, 'lon': -73.7419, 'tz_id': 'America/New_York', 'localtime_epoch': 1757523652, 'localtime': '2025-09-10 13:00'}, 'current': {'last_updated_epoch': 1757523600, 'last_updated': '2025-09-10 13:00', 'temp_c': 18.3, 'temp_f': 64.9, 'is_day': 1, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/day/122.png', 'code': 1009}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 42, 'wind_dir': 'NE', 'pressure_mb': 1022.0, 'pressure_in': 30.18, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 70, 'cloud': 100, 'feelslike_c': 18.3, 'feelslike_f': 64.9, 'windchill_c': 21.8, 'windchill_f': 71.2, 'heatindex_c': 23.4, 'heatindex_f': 74.2, 'dewpoint_c': 15.6, 'dewpoint_f': 60.2, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.4, 'gust_mph': 14.3, 'gust_kph': 23.0}}\", \"score\": 0.9463999}]\n",
      "\n",
      "üß† STEP 2 - AGENT REASONING:\n",
      "   Now I know it's Wednesday, September 10, 2025. Now I need to search for current weather information in Queens. I'll use Tavily search since this is current, real-time information.Great! I have current weather information for Queens, New York. Let me parse this data and present it in a clear, user-friendly way. The data shows:\n",
      "\n",
      "- Location: Queens Village, New York\n",
      "- Temperature: 64.9¬∞F (18.3¬∞C)\n",
      "- Condition: Overcast\n",
      "- Wind: 11.2 mph from the Northeast\n",
      "- Humidity: 70%\n",
      "- No precipitation\n",
      "- Feels like: 64.9¬∞F\n",
      "- Visibility: 9 miles\n",
      "- Last updated: September 10, 2025 at 1:00 PM local time\n",
      "\n",
      "This gives a good picture of the current weather conditions.\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   Based on the current weather data for Queens, New York today\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   (Wednesday, September 10, 2025\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   ), here are the conditions:\n",
      "\n",
      "**Current\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   Weather in Queens:**\n",
      "- **Temperature:**\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   65¬∞F (18¬∞C)\n",
      "- **Conditions\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   :** Overcast skies\n",
      "- **Feels\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   like:** 65¬∞F\n",
      "- **Win\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   d:** 11 mph from the northeast\n",
      "- **\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   Humidity:** 70%\n",
      "- **\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   Visibility:** 9 miles\n",
      "- **No\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   precipitation** currently\n",
      "\n",
      "It\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   's a mild, cloudy day in\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   Queens with comfortable temperatures in\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   the mid-60s. The over\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   cast conditions mean it's quite\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   cloudy, but\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   there's no rain at\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   the moment. The northeast wind is providing\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   a gentle breeze. Perfect\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   weather for light outdoor activities, though you\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   might want to bring a light jacket if\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   you're planning to be outside for extende\n",
      "\n",
      "ü§ñ ASSISTANT RESPONSE:\n",
      "   d periods.\n",
      "\n",
      "‚úÖ QUERY COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "user_agent_trace(queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbbb9f0-31cf-4c06-a18d-b3376041cea6",
   "metadata": {},
   "source": [
    "# Workflow Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f732d01-9317-4e53-8ddc-4f83a67ef897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ToolNode to handle LangChain tool calls\n",
    "tool_node = ToolNode(available_tools)\n",
    "\n",
    "# Bind the custom LangChain tools to the LLM\n",
    "model_with_tools = claude.bind_tools(available_tools)\n",
    "\n",
    "# # Define workflow functions\n",
    "\n",
    "# ## Create a stopping function\n",
    "# Use MessagesState to define the state of the stopping function\n",
    "def should_continue(state: MessagesState) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether the agent should continue processing or end.\n",
    "    Args:\n",
    "        state: The current state of the graph, containing messages.\n",
    "    Returns:\n",
    "        \"tools\" if the last message contains tool calls, END otherwise.\n",
    "    \"\"\"\n",
    "    # Get the last message from the state\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # Check if the last message is an AIMessage and has tool_calls\n",
    "    # LangChain tools bound with .bind_tools() appear in `tool_calls`\n",
    "    # Adjust this logic if necessary based on how built-in tool calls are represented.\n",
    "    if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "         # Check specifically for LangChain tool calls\n",
    "        if any(tc.get('name') in [t.name for t in available_tools] for tc in last_message.tool_calls):\n",
    "             return \"tools\" # Route to the LangChain tool node\n",
    "\n",
    "    # Check for Google built-in tool calls (heuristic, might need adjustment)\n",
    "    if isinstance(last_message, AIMessage) and last_message.additional_kwargs.get(\"tool_calls\"):\n",
    "         # The model might handle these directly without needing an explicit \"tools\" step in the graph\n",
    "         # If the model *responds* with content after using a built-in tool, we might want to end.\n",
    "         # If it needs explicit execution confirmation/results, the graph needs adjustment.\n",
    "         # For now, assume the model handles built-in tools and we end if no *LangChain* tools are called.\n",
    "         pass # Let the flow continue to END if no LangChain tools were called\n",
    "\n",
    "    # End the conversation if no explicit LangChain tool calls are present\n",
    "    return END\n",
    "\n",
    "\n",
    "## Create the system prompt \n",
    "def create_agent_prompt():\n",
    "    \"\"\"\n",
    "    Creates a comprehensive prompt template for the workflow agent.\n",
    "    \"\"\"\n",
    "    system_template = get_prompt()\n",
    "\n",
    "    # Create the full prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_template),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ])\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def call_model_with_prompt(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Enhanced agent node function that uses a prompt template.\n",
    "    Args:\n",
    "        state: The current state of the graph.\n",
    "    Returns:\n",
    "        A dictionary containing the updated messages list.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Get the prompt template\n",
    "    prompt_template = create_agent_prompt()\n",
    "    \n",
    "    # Format the prompt with current messages\n",
    "    # This creates a properly formatted conversation with system instructions\n",
    "    formatted_messages = prompt_template.format_messages(messages=messages)\n",
    "    \n",
    "    # Invoke the model with the formatted prompt\n",
    "    response = model_with_tools.invoke(formatted_messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "    \n",
    "## Create a dynamic tool caller (Agent Node)\n",
    "def call_model(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    The main agent node function. Invokes the LLM.\n",
    "    Args:\n",
    "        state: The current state of the graph.\n",
    "    Returns:\n",
    "        A dictionary containing the updated messages list.\n",
    "    \"\"\"\n",
    "    # Note: The original function had logic to handle tool responses directly.\n",
    "    # In a typical LangGraph setup, the ToolNode handles executing tools\n",
    "    # and adding ToolMessages back to the state. This node should primarily\n",
    "    # focus on calling the LLM with the current state.\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    # The response from the LLM (which might include content and/or tool calls)\n",
    "    # is added back to the state.\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c024f2fc-ac69-424e-a338-d628ee910804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes for chatbot (agent) and LangChain tools\n",
    "workflow.add_node(\"chatbot\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node) # Node to execute LangChain tools\n",
    "\n",
    "# Connect the START node to the chatbot\n",
    "workflow.set_entry_point(\"chatbot\")\n",
    "\n",
    "# Define conditional edges:\n",
    "# After chatbot node, check if we should continue (call tools) or end.\n",
    "workflow.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\", # If should_continue returns \"tools\", go to the tools node\n",
    "        END: END          # If should_continue returns END, finish the graph\n",
    "    }\n",
    ")\n",
    "\n",
    "# After the tools node executes tools, always go back to the chatbot node\n",
    "# The ToolNode adds ToolMessages, and the chatbot node will process them.\n",
    "workflow.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Adding memory\n",
    "# Set up memory and compile the workflow\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f9f926-f480-4f1e-abfa-9991e7a9ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Organize chatbot outputs with memory\n",
    "# ## Streaming outputs with memory (Alternative Streaming Approach)\n",
    "\n",
    "# Set up a streaming function for a single user session\n",
    "def stream_memory_responses(user_input: str, thread_id: str):\n",
    "    \"\"\"\n",
    "    Streams all events from the graph execution for a single input.\n",
    "    Args:\n",
    "        user_input: The user's input string.\n",
    "        thread_id: The unique identifier for the conversation thread.\n",
    "    \"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    print(f\"\\n--- Streaming Events (Thread: {thread_id}, Input: '{user_input}') ---\")\n",
    "\n",
    "    # Stream the events in the graph\n",
    "    for event in app.stream({\"messages\": [(\"user\", user_input)]}, config):\n",
    "\n",
    "        # Return the agent's last response\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and value[\"messages\"]:\n",
    "                print(\"Agent:\", value[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f57f6a9-d767-4e65-bb23-3d932419aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Agentic LangGraph Script...\n",
      "\n",
      "--- Streaming Events (Thread: thread-example-3-stream, Input: 'What is the Parthenon?') ---\n",
      "Agent: [AIMessage(content=[{'signature': 'EoYDCkYIBxgCKkClVejuLC9uw92U3USqAkjjqFFUJfhB9Acgbq5E765Rw8sEL8ghsO0IIfitfv4wxlh0MNtP08WGQeO7fTCwTgRZEgyULxtP3XHq0NO0BUUaDGBObv6KBztNtNF8nCIwiM+aU83Thw1qwTMbM3GeNEAlUJ3HCEP+V4ht3HphXDRmhtjuFLd4+4+M5smRiCVBKu0BdoWap0IdGIZyo7LKCgpfkwFj2ApgIS6M6x7oijY1cIVzxtueu2WLi7M7UMGUerYgOAEYAmSf9oql3pRK0XWhgI9jlVIQ55huiErINnGME2uVI7hcgH4UjvD5dsnhkEAryfb3giraaDSMAwrhiuI0THB5aKswPY5L3irkWnaK7oCOtVdSA+/Z9c/NO92wKA46moK9cC3x1gvanSm8rs/CgtGWtoDIvRE8fHiEIBlc/Q9q5nyPFlSDyuuY8Q+H+oJ7m2Ag6isjPY3gSzSau/cavTOp/4Tm7pEp5E+mwOvBPtrc4Wmx85uK0Vexe13FGAE=', 'thinking': 'The user is asking about the Parthenon, which is a famous ancient Greek temple. This is a historical and general knowledge question, so I should use the Wikipedia search function to get comprehensive information about it.', 'type': 'thinking'}, {'id': 'toolu_01UDt1imfXAYZYCfLjHN1TZD', 'input': {'__arg1': 'Parthenon'}, 'name': 'wikipedia_query_run', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_015WnpiikJqhwGa84xjbzXiC', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 826, 'output_tokens': 112, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--16bbf492-6477-41cb-8e17-a3d2231af1e8-0', tool_calls=[{'name': 'wikipedia_query_run', 'args': {'__arg1': 'Parthenon'}, 'id': 'toolu_01UDt1imfXAYZYCfLjHN1TZD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 826, 'output_tokens': 112, 'total_tokens': 938, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n",
      "Making Wikipedia API call for: Parthenon...\n",
      "Agent: [ToolMessage(content=\"Page: Parthenon\\nSummary: The Parthenon (; Ancient Greek: Œ†Œ±œÅŒ∏ŒµŒΩœéŒΩ, romanized: Parthen≈çn [par.t ∞e.n…îÃåÀên]; Greek: Œ†Œ±œÅŒ∏ŒµŒΩœéŒΩŒ±œÇ, romanized: Parthen√≥nas [parŒ∏eÀànonas]) is a former temple on the Athenian Acropolis, Greece, that was dedicated to the goddess Athena. Its decorative sculptures are considered some of the high points of classical Greek art, and the Parthenon is considered an enduring symbol of ancient Greece, democracy, and Western civilization. \\nThe Parthenon was built in the 5th century BC in thanksgiving for the Greek victory over the Persian invaders during the Greco-Persian Wars. Like most Greek temples, the Parthenon also served as the city treasury. Construction started in 447 BC when the Delian League was at the peak of its power. It was completed in 438 BC; work on the artwork and decorations continued until 432 BC. For a time, it served as the treasury of the Delian League, which later became the Athenian Empire.\\nIn the final decade of the 6th century AD, the Parthenon was converted into a Christian church dedicated to the Virgin Mary. After the Ottoman conquest in the mid-15th century, it became a mosque. In the Morean War, a Venetian bomb landed on the Parthenon, which the Ottomans had used as a munitions dump, during the 1687 siege of the Acropolis. The resulting explosion severely damaged the Parthenon. From 1800 to 1803, the 7th Earl of Elgin controversially removed many of the surviving sculptures and subsequently shipped them to England where they are now known as the Elgin Marbles or Parthenon marbles. Since 1975, numerous large-scale restoration projects have been undertaken to preserve remaining artefacts and ensure its structural integrity.\\n\\nPage: Parthenon (Nashville)\\nSummary: The Parthenon in Centennial Park, Nashville, Tennessee, United States, is a full-scale replica of the original Parthenon in Athens, Greece. It was designed by architect William Crawford Smith and built in 1897 as part of the Tennessee Centennial Exposition.\\nToday, the Parthenon, which functions as an art museum, stands as the centerpiece of Centennial Park, a public park just west of downtown Nashville. Alan LeQuire's 1990 re-creation of the Athena Parthenos statue in the naos (the east room of the main hall) is the focus of the Parthenon just as it was in ancient Greece. Since the building is complete and its decorations were polychromed (painted in colors) as close to the presumed original as possible, this replica of the original Parthenon in Athens serves as a monument to what is considered the pinnacle of classical architecture. The plaster replicas of the Parthenon Marbles found in the Treasury Room (the west room of the main hall) are direct casts of the original sculptures which adorned the pediments of the Athenian Parthenon, dating to 438 BC. The surviving originals are housed in the British Museum in London and at the Acropolis Museum in Athens.\\n\\n\\n\\nSources:\\nhttps://en.wikipedia.org/wiki/Parthenon\", name='wikipedia_query_run', id='a06e9d7f-2678-4be6-9a5b-a63929f8ff1f', tool_call_id='toolu_01UDt1imfXAYZYCfLjHN1TZD')]\n",
      "Agent: [AIMessage(content=[{'signature': 'Es8ICkYIBxgCKkBZenD1ZuMP/Sl//Rsvk7mX5IEnFPriclpRdB1i/Dc7L6z1pcuB/Af1+QP5juqO4/jdT38l7xRiXWyXW9KJWF0LEgzv61vuk23hIwAWJBIaDE28rbelQfzzZIi6sCIwEb6N72DdieZiDRdaLQsNXYcMLXubJqfxAMNQwsZbY0r4rE++f8Qp9mv9bB3cHIOyKrYHwpaICDgxPoF8zY4yKUzZXF2hqf8sILsINiNH3BhoSt4BKxFQxW3mex+R+h+SSqhtucGTC40JMiH4ukgeGUsld3PhYd/urQ0BB4vxAyRjQjS8Jspj1fEB41awjlyv3BhJha8Y0NZ8kOv2gZVFxiyaaOR/BcATwNM9zwCr+nqRQoxEcSNGW6958+9Ww5MrM3hh+Ap/NH9RGRCGGA6s5s3Ot4MqLrYirjn/m1Hby2Mbn7TqlgG5bhy6Asgw/ROVh6W98EPQt3mPSK00sv4XxtKLB2Le6Yc+iF3T+YkGyvl9o4JODBe/kL6PeogDiw8vJdeRadAEGMZ8GYSBvN4aEYyztXRzBmzY6Jhds/3tXtp2ghdOop1tzJ+vxYAPkAWRumUYHRt2AXjOLC6VJC8TvysIp5vf5lT4Nw79k3Vi0z43rxcdHsteEMPjvI/apYSwWO/68w5vYT06yiCsOnyZ+6JMWHMaP6lhZAMMf/0KEv7mufG5voshhhzkybKrlN7vzI7PCkgrMlDe3NRxhS1G1U3LLXiCQ1iZs25Z7XYkkU0rE/hSErr3FaY1j5SCQndWnvUlsto4QmYckttAQ+9niyYLVeqAgio4JLILV8tJOoq/U4Zk5NcsG/fgaz0072M/UjWH5anaRBkcijBZQ299hB+vCj7yhsAylSEZNn+NIXZUloKfa14fdSz0/UeMOn8SM/pKGY3CtaKAYb8Kf8fOdpexInzcVDg7+OGjGb9A2DCoiO53oJk2/fhBksaftzr1g3ZU9hUBDNaOeghmP5bhha1QMDPPZajBp7qpN+UEvQboB2DjL0kmWmoJlEjDQmWf9OwX0k5v4h9lT8iNgfvq8dV/NjfJwsDcU85bxBCC548kFoo0OOcMrub0X4AMHQMYNQ3Y2vJ3mkHH2XCAtk0uAMcoPjy4S8od0IdrdtZrRFoTj7fRH3JiEnRdJbn/56I21YjlZXYllmVc6lVn+AB4xAhk9UwaIt/84qNmNiWhCiOyPnYyPjXgNNgoLvgX5C4NNIXz+oSbSL1VkTjQ3ss26XtdM/NfORPB5J/ga4uxv/AWbu3PR8/rZP1kvvhdNrZA26QiKHgxcJTFIojb98FpvPKYeS7H79Zj2HIirBZRk4cqOWCdhdrjDDg0Bv4U/6w2vLoa6zL/KATmBSglZdaacB3WYV52nNExqI8DMWFa4H1T3IPggktQRf/oQOJhwo35txUsWoKqsva1vQK0gIu3z2Tjf3bQ5y/yq4rltNYSYQLD+YGOJTx+qKgYAQ==', 'thinking': \"Great! I have comprehensive information about the Parthenon from Wikipedia. The search returned information about both the original Parthenon in Athens and the replica in Nashville. The user is most likely asking about the original ancient Greek temple, so I'll focus primarily on that while briefly mentioning the Nashville replica as additional context.\\n\\nThe key points about the Parthenon are:\\n1. It's an ancient Greek temple on the Athenian Acropolis\\n2. Dedicated to goddess Athena\\n3. Built in the 5th century BC (447-432 BC)\\n4. Considered a symbol of ancient Greece, democracy, and Western civilization\\n5. Famous for its decorative sculptures (high points of classical Greek art)\\n6. Built to celebrate victory over the Persians\\n7. Later converted to Christian church, then mosque\\n8. Severely damaged in 1687 by Venetian bomb\\n9. Many sculptures removed by Lord Elgin (now Elgin Marbles)\\n10. Ongoing restoration projects since 1975\", 'type': 'thinking'}, {'text': 'The Parthenon is a magnificent ancient Greek temple located on the Athenian Acropolis in Greece. Here are the key details about this iconic structure:\\n\\n## **Historical Background**\\n- **Built**: 5th century BC (construction: 447-438 BC, decorations completed by 432 BC)\\n- **Purpose**: Dedicated to the goddess Athena, the patron deity of Athens\\n- **Significance**: Built to celebrate the Greek victory over the Persian invaders during the Greco-Persian Wars\\n\\n## **Architectural and Cultural Importance**\\n- Considered one of the finest examples of classical Greek architecture\\n- Its decorative sculptures are regarded as high points of classical Greek art\\n- Serves as an enduring symbol of ancient Greece, democracy, and Western civilization\\n- Originally functioned both as a temple and as the treasury of the Delian League (later the Athenian Empire)\\n\\n## **Historical Transformations**\\n- **6th century AD**: Converted into a Christian church dedicated to the Virgin Mary\\n- **Mid-15th century**: Became a mosque under Ottoman rule\\n- **1687**: Severely damaged when a Venetian bomb hit it during the siege of the Acropolis (the Ottomans had been using it as a munitions dump)\\n\\n## **Modern History**\\n- **1800-1803**: The 7th Earl of Elgin controversially removed many surviving sculptures, now known as the \"Elgin Marbles\" or \"Parthenon Marbles,\" which are housed in the British Museum in London\\n- **Since 1975**: Ongoing large-scale restoration projects to preserve the structure and remaining artifacts\\n\\nThe Parthenon remains one of the world\\'s most recognizable monuments and continues to inspire architecture and art today. There\\'s even a full-scale replica in Nashville, Tennessee, built in 1897!', 'type': 'text'}], additional_kwargs={}, response_metadata={'id': 'msg_01STZpTyptyLZGH28rywT9oi', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1726, 'output_tokens': 650, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--d799d3c1-d73c-4410-bd69-3d8d999f753f-0', usage_metadata={'input_tokens': 1726, 'output_tokens': 650, 'total_tokens': 2376, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Agentic LangGraph Script...\")\n",
    "\n",
    "# --- Example 3: Streaming all graph events ---\n",
    "thread3_id = \"thread-example-3-stream\"\n",
    "stream_memory_responses(\"What is the Parthenon?\", thread3_id)\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a86994f-ae73-4e50-9ab9-44602e227072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Agentic LangGraph Script...\n",
      "ü§ñ Interactive Chat Session\n",
      "==================================================\n",
      "Commands:\n",
      "- Type your message to chat with the agent\n",
      "- Type 'quit', 'exit', or 'bye' to end the session\n",
      "- Type 'clear' to start a new conversation thread\n",
      "- Type 'help' to see these commands again\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Message 1] You:  hey, how's it going?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Processing... (Thread: interactive-thread-b4abe117)\n",
      "\n",
      "--- Streaming Events (Thread: interactive-thread-b4abe117, Input: 'hey, how's it going?') ---\n",
      "Agent: [AIMessage(content=[{'signature': 'EuQDCkYIBxgCKkAE3++sZjdkuzD+F5E6bvi7OkM8VRcyal7v6onh9DtUNC91rXZSiSa9AUKr5BZTqT3te26SC7gQPBmxGEsiBKPtEgz1rEmpcfTqe7G2xDwaDKkdyyJpNfurieUHIyIwdvuUoQv+5qpFtGsJdUvHlzvg/x7p4glwBXVJ7g8NnP8ICTGfBX4zmBEPVRMraSWuKssCAI0SlzuKA5mqFitMW48THvn46TkOatx64t+UHGC1Df7hqlATYZ5OcZarBPaEx0h63Coq679+vNqORkJ4QNqpXHfbWpXsbfc8kxhNPnqLNCEB9doCF5pCnzLQF6rVDjTsjZnQFkIOL6nx8NmNo4J02NtqNkt2yS8wRlv41DLFJqzs6i8AlsilqCeBpnkBIy8s8/zvh8GszDlyq6dX6mTfQQXQgm4XTo8yTJ0JhCiNdHW4zMYsnFcWLf+cwaloxjlniG90e8sYlHFM2h67Wtj6TjG3uSvwLt8vJFNVLEGXDXeSPqzZP5ISo6iComRyhn61sZpvnmyX6XC/CQv/MvHypmD/e+xYnB46+JM6b8JKSU0MX8zDSRzrDT3fZaCWAXlKORUQl1RlCWeJHbjWhFd2Dr5YEfIzksj+BEkAwCAPw1NLZtj6tnqrqeGauhgB', 'thinking': 'The user is just greeting me casually with \"hey, how\\'s it going?\" This is a simple social greeting that doesn\\'t require any tools or specific information gathering. I should respond in a friendly, conversational way without using any of the available functions since they\\'re not needed for this type of interaction.', 'type': 'thinking'}, {'text': \"Hey there! I'm doing well, thanks for asking! I'm here and ready to help with whatever you need. How are you doing today? Is there anything I can assist you with?\", 'type': 'text'}], additional_kwargs={}, response_metadata={'id': 'msg_01KGTzxuyx72n5g8F6vGbbr9', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 825, 'output_tokens': 113, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--0a7cc008-06f9-4486-b4c2-23890877958a-0', usage_metadata={'input_tokens': 825, 'output_tokens': 113, 'total_tokens': 938, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Message 2] You:  yeah, so I'm loooking for some info on NotebookLM? specifically what is it? benefits / limitations and how it can help me conduct research. provide an overview of the product with some useful tips & tricks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Processing... (Thread: interactive-thread-b4abe117)\n",
      "\n",
      "--- Streaming Events (Thread: interactive-thread-b4abe117, Input: 'yeah, so I'm loooking for some info on NotebookLM? specifically what is it? benefits / limitations and how it can help me conduct research. provide an overview of the product with some useful tips & tricks') ---\n",
      "Agent: [AIMessage(content=[{'signature': 'Et4DCkYIBxgCKkBPScxmUsRP8TJ5Uis3NoFc2qk9youaFrvVyUGacGPK29NB5qSYX4I+yf4DaevpFHFTr/RsRngnha7jTKJIba9sEgzYvHFhEGAu6POhMaMaDE37ALgpadb6Gm0gYyIwygh2rTGsB/LUrg2hXDvS1ufov/sXje2ggSx4q0pw1R5tGKMfBmOwvMX5Zn3dXdAEKsUCIj0hZNlJC53kuCOr+bY9MlU9a8Z3Bq2dUkXgpH4IXGwiH6/feOxxlqyWHGGO0f1jE0J7y8MnbpsXKgXDIRnZ3WC+kU1RKMFf8tSyBYg9X6wXlWuyHhq4qkTcqAK/Y4tUlDk0eCCpy5raLNUaiPaVpu6jZ1YrHLcwYrVVdktd/jwN0LkrGv3HLvJurUkK6BIZDTvWLYvXTRRDZ4vpBOc+dRgIbQDS3R1jMcQzIyVN6rgOhYVUsGIsHTfuwSq6atHJI8cVrwFE84iwlsvO+TPUEAdNszw6ecskwDLqmytSDZ85yBE394LQU9vsk3PrJWI+hfp9rDwi3FuXTQWWF+y7sYMvjBNmQSBe+ZGbjPtJqQ9f+aBxsw6BB+Nk+pwdiOArA4R11Q+iJHfv8MUCv33tdYKkMHXRYMS73lynGWPUm4wkEr/OVBgB', 'thinking': 'The user is asking about NotebookLM, which is a Google product. This is current technology information, so I should search for the most up-to-date information about it. Let me search for comprehensive information about NotebookLM including what it is, benefits, limitations, and how it can help with research.', 'type': 'thinking'}, {'id': 'toolu_01F7x7BxefLQnn1MLjMsNBgc', 'input': {'__arg1': 'NotebookLM Google AI research tool overview benefits limitations features'}, 'name': 'tavily_search_results', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01F7Xx21aNLpaFd2mS6upea2', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 917, 'output_tokens': 147, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--4d6fa08b-5d3a-44c6-921b-353be3b12aab-0', tool_calls=[{'name': 'tavily_search_results', 'args': {'__arg1': 'NotebookLM Google AI research tool overview benefits limitations features'}, 'id': 'toolu_01F7x7BxefLQnn1MLjMsNBgc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 917, 'output_tokens': 147, 'total_tokens': 1064, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n",
      "Making Tavily API call for: NotebookLM Google AI research tool overview benefi...\n",
      "Agent: [ToolMessage(content='[{\"title\": \"Geekflare What Is NotebookLM? Features, Benefits, and Use Cases\", \"url\": \"https://geekflare.com/guide/what-is-notebooklm/\", \"content\": \"NotebookLM is an experimental AI-powered research and note-taking tool from Google, designed to simplify complex documents through summaries, interactive Q&A, and podcast-style audio overviews, providing users with concise insights and engaging content summaries. NotebookLM is an experimental AI-powered research and note-taking tool from Google that improves user interaction with complex documents. All features are based on the user‚Äôs own documents, making NotebookLM a powerful tool for streamlined research and note-taking. NotebookLM is an AI-powered note-taking and research tool developed by Google, designed to enhance the way users interact with and comprehend information. * **Grounded in User Content**: Unlike many AI tools that rely on large, pre-trained datasets, NotebookLM specializes in analyzing the documents you upload, ensuring that their responses are directly relevant to your specific research or project.\", \"score\": 0.85797083}]', name='tavily_search_results', id='b2ef9de0-62e2-4657-967f-c63aa4e3d578', tool_call_id='toolu_01F7x7BxefLQnn1MLjMsNBgc')]\n",
      "Agent: [AIMessage(content=[{'signature': 'EosDCkYIBxgCKkCbw4SA/KBk9gn1OTkuK+yl2rKuUjZVWNBup6gbXe9gXHYqLhQrU2/X7RwV/aYiJRQDJ4/V7DE2Cn6Hl23ot6glEgwhguVIGdVe6fQcQkcaDEInREvWMD/BJ9SkGSIw0lb6cAzgZCD+dk5wz/jwONFlTLaRjU0w/CShle35+pdR8rG/+wCZtRdiym/ewNiFKvIBgn3gbIYoIJy2Op9X+ONMYoIDpKNTi4cc5pntTErhquKwtlXn0sr9jeRvYFJ5hjNCQviP5YlsQC5sNxbUY8VnnaD+y1SANVQMfDfvnmq3JKG8FTmn7sZXqRtUCcbT8a0I4b76d0aeSMqqMfR2mW0wSCrg2013LX6JylSJ8h94ADOJHsf9tAGLRaLx9qHHjaOmcLW4WDJ6xWijspGU+IDJQgA1vteXtL3zwbiypHz0auetGW2zs+Z1U/Tj2lAHE+dctLDyGK7eIPWjG+l4+ViskgVwVfrXbLLVzfpm+zxrrrWdEgTMkwdNsGDxASww/MVXCCsYAQ==', 'thinking': \"I got some good initial information, but I'd like to get more comprehensive details about NotebookLM, especially about its specific features, limitations, and research capabilities. Let me search for more detailed information.\", 'type': 'thinking'}, {'id': 'toolu_01FvL2bbKoJA6TjVhN5e8u1S', 'input': {'__arg1': 'NotebookLM tips tricks research workflow how to use effectively 2024'}, 'name': 'tavily_search_results', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_015ct46yi4HpPs4WkAnW5Hx4', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1345, 'output_tokens': 125, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--55147880-cc3d-450b-ac50-7db776cf5cd8-0', tool_calls=[{'name': 'tavily_search_results', 'args': {'__arg1': 'NotebookLM tips tricks research workflow how to use effectively 2024'}, 'id': 'toolu_01FvL2bbKoJA6TjVhN5e8u1S', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1345, 'output_tokens': 125, 'total_tokens': 1470, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n",
      "Making Tavily API call for: NotebookLM tips tricks research workflow how to us...\n",
      "Agent: [ToolMessage(content='[{\"title\": \"NotebookLM: A Guide With Practical Examples\", \"url\": \"https://www.datacamp.com/tutorial/notebooklm\", \"content\": \"Sep 23, 2024 ‚Äî When querying NotebookLM, make sure your questions are clear and specific . Asking vague questions can result in broad or less-than-helpful\", \"score\": 0.6698534}]', name='tavily_search_results', id='0b33c452-cb1f-460d-9895-9ede634e032d', tool_call_id='toolu_01FvL2bbKoJA6TjVhN5e8u1S')]\n",
      "Agent: [AIMessage(content=[{'signature': 'EpsCCkYIBxgCKkAa8kENdRixaYVSYH+LMFf/7CBPiPJiKa+J/LYwEHVgn331wlReetrkuCfb+jTscda5oKonuSNy3DQZQavScGJPEgwqw3oKV0qLJvnCBEgaDGa3wkHhFJPYmDGHdyIwmHWYX5uUHXQJ/c3Dvbp+AVcVVagzn4mbGApw66i5IvX1hCZntIVnZ5AZl7Y3EFTGKoIBeur9dS5+KoDkiP2+MQ64Jy+LFEDWXaXK5ViN96SUorFbMXUK6QSBkPR3EBXlRXm/siBXh5G8BrFGcWKfqFp/lEMnTbT5ZTH/rT/xYDIFa/O+7yQobDvFdTMP3siZJbncNkmtuD3v49sBJEjWAaOqV/JmMeJK7nAjkrXgxWuVgi26ORgB', 'thinking': \"I need more comprehensive information. Let me search for more details about NotebookLM's features and limitations.\", 'type': 'thinking'}, {'id': 'toolu_013GMQHntqAobhz6sFeTrsX7', 'input': {'__arg1': '\"NotebookLM\" features limitations audio overview podcast research assistant Google'}, 'name': 'tavily_search_results', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01RBAPJFjGdCpk3M8tCkBJAy', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1584, 'output_tokens': 104, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--b35f331a-3a43-4e71-8d7f-812ee998ab98-0', tool_calls=[{'name': 'tavily_search_results', 'args': {'__arg1': '\"NotebookLM\" features limitations audio overview podcast research assistant Google'}, 'id': 'toolu_013GMQHntqAobhz6sFeTrsX7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1584, 'output_tokens': 104, 'total_tokens': 1688, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n",
      "Making Tavily API call for: \"NotebookLM\" features limitations audio overview p...\n",
      "Agent: [ToolMessage(content='[{\"title\": \"Google Support Generate Audio Overview in NotebookLM - NotebookLM Help\", \"url\": \"https://support.google.com/notebooklm/answer/16212820?hl=en\", \"content\": \"Important: At this time, the NotebookLM mobile app may have limitations to this feature . Learn more about the supported features in NotebookLM mobile app. Audio Overviews are deep-dive discussions be\", \"score\": 0.6952351}]', name='tavily_search_results', id='0a2079e2-dce5-4be1-afa0-2ec3eaafd2ad', tool_call_id='toolu_013GMQHntqAobhz6sFeTrsX7')]\n",
      "Agent: [AIMessage(content=[{'signature': 'EooCCkYIBxgCKkC0mS8XVnp6l3rmfgQXu1YDR7cCSo8jD1dx/2aWuegIgtivwBjJtMfPM5ROgNIhv1QizynkEO+Pjy96ytJ0jrUuEgzCkABXA2qpbjxzFGoaDD6HBxxbdzJJrRwZBCIwImxuMdXaA/6Mh+VrGyWvDd9A2a1BusMOYqUyE3/1ZJ6NurnlyeH6DY7dE5Sac06gKnKillTEw37wTpuj1xa/6fGfngRGLHna7TQuC+LwVXjyujRsS/c5ec8i47ijj0nu5gwVmWuovFdi2JjN8iJahDHOwiZSBBBaO6h5nwrIsAwM+/YTETWPuR21PAaUedBrY6oJVCX7CD73BDGkL7GD3F6T9AQYAQ==', 'thinking': \"Let me get more comprehensive information about NotebookLM's current capabilities and limitations.\", 'type': 'thinking'}, {'id': 'toolu_01NAk5xaiKJvTKjZrzpzkbxq', 'input': {'__arg1': 'NotebookLM complete guide what can it do document types supported limitations 2024'}, 'name': 'tavily_search_results', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_015Ewd7ke1qWYjFZQX2THPzd', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1821, 'output_tokens': 102, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--2d37e3d6-1401-43e2-b0e2-77984d78bb66-0', tool_calls=[{'name': 'tavily_search_results', 'args': {'__arg1': 'NotebookLM complete guide what can it do document types supported limitations 2024'}, 'id': 'toolu_01NAk5xaiKJvTKjZrzpzkbxq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1821, 'output_tokens': 102, 'total_tokens': 1923, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n",
      "Making Tavily API call for: NotebookLM complete guide what can it do document ...\n",
      "Agent: [ToolMessage(content='[{\"title\": \"Google NotebookLM Complete Course\", \"url\": \"https://www.futurepedia.io/courses/google-notebooklm-complete-course\", \"content\": \"Google NotebookLM Complete Course. Learn to organize, summarize, and transform your files with Google NotebookLM . Whether you‚Äôre managing research, turning PDFs into podcasts, or building study guides , this course shows you how to unlock deeper insights with AI.\", \"score\": 0.50930125}]', name='tavily_search_results', id='6832e0d9-eb18-4225-a9b4-cf78070a3ec7', tool_call_id='toolu_01NAk5xaiKJvTKjZrzpzkbxq')]\n",
      "Agent: [AIMessage(content=[{'signature': 'EpUCCkYIBxgCKkD65rUXGHugxhHZHGt3cziXnevTlHEjedcZQ/QHfpRbbA4QfDmxEB9xGFEJpDVtG6BEIMQJPWGXpTOZM7EOVY1UEgy6QG/B/gWzRv6gf9gaDOzS+6OCY985Gy+psyIwl8OfzYjz7Z7c3+NJKF9SxOX6rHWQnm+iokpwsP0pr4mTCNka5eRVFL5q0NxWDQW8Kn0Ek6qQ1SK/lvEIiYktNQ2WPcM7boxSzLArmz26WzdZMYR6jRxYod90MyN9k/aHSIEksuCPQZDJbbT1sPW+BFSz+kYN4KrzXCbdX7OnEWdDydnJag2kq5FVgetiuEv4rOYI/s1Ws5fQ9OaADtTCxhyYekiT+67azdlwWjzN+BgB', 'thinking': \"Let me search for more specific information about NotebookLM's research capabilities and practical use cases.\", 'type': 'thinking'}, {'id': 'toolu_01DRK5jCbC6pkUbnBTozFHt9', 'input': {'__arg1': 'NotebookLM research capabilities document analysis PDF upload study guide creation'}, 'name': 'tavily_search_results', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01QeH9mPoFy4dYXDkqfN5HcK', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2056, 'output_tokens': 101, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--dc72a1cf-b662-4d06-931c-ab962b890d91-0', tool_calls=[{'name': 'tavily_search_results', 'args': {'__arg1': 'NotebookLM research capabilities document analysis PDF upload study guide creation'}, 'id': 'toolu_01DRK5jCbC6pkUbnBTozFHt9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2056, 'output_tokens': 101, 'total_tokens': 2157, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n",
      "Making Tavily API call for: NotebookLM research capabilities document analysis...\n",
      "Agent: [ToolMessage(content='[{\"title\": \"NotebookLM : Revolutionizing Research with AI Assistance\", \"url\": \"https://www.toolify.ai/ai-news/notebooklm-revolutionizing-research-with-ai-assistance-3394340\", \"content\": \"Study Guide Creation : With NotebookLM , you can easily create study guides based on your uploaded documents . Study Guide Generation. Creates study guides by summarizing passages and generating questions.\", \"score\": 0.8014549}]', name='tavily_search_results', id='0fdf7224-f8e8-43eb-b541-f7b734c56cf4', tool_call_id='toolu_01DRK5jCbC6pkUbnBTozFHt9')]\n",
      "Agent: [AIMessage(content=[{'signature': 'EtECCkYIBxgCKkDGTO2TGve/kt6gDQsL9CvktgAFxqyNRU1AFCdoVN2JAxlVHZL6qnKfTeQkUUF18GnNFpTAeZdaSE0asuSKnp/MEgyUhcmcLLLhT37kCdUaDETglEcfgWmrBsb0JCIwiE36Mt16PhNTfMKHD2Dn9/1OwSwejn4FZzXzEJU2tJCN/1JegdyRl7a4a4YJsdT/KrgB6yc4XTtpSC5yfb5sNChe0flliy4dmFBd/gqqX5u9opkVFB/9ArSKmZQ1iF+ZMWTrttjHYP8BMfP8cLbbZiWmYduFQv2BnTRZVjO3dJGuiRgyb5SvO+76H/vArKfVQVj3JB1clr+CRSjp2NgX+XfFkQBAcJlUQROV+a68eBHvS4Mxm9uz0+AaOVsUlcqJT6p9I9UOdVn/eW1VUs4F8GzzB8WF7mjTeNwEOIV8zfS89MF25hKYeutYRBgB', 'thinking': \"Now I have enough information to provide a comprehensive overview. Let me compile what I've learned about NotebookLM and provide a useful overview with tips and tricks.\", 'type': 'thinking'}, {'text': '# NotebookLM: Complete Overview & Research Guide\\n\\n## What is NotebookLM?\\n\\nNotebookLM is Google\\'s experimental AI-powered research and note-taking tool designed to help users interact with and analyze their own documents more effectively. Unlike general AI tools that rely on broad internet knowledge, NotebookLM is **grounded in your specific content** - it only works with documents you upload, ensuring responses are directly relevant to your research.\\n\\n## Key Features\\n\\n### üìÑ **Document Analysis**\\n- Upload PDFs, Google Docs, text files, slides, and web articles\\n- AI analyzes and understands your specific content\\n- Creates summaries and extracts key insights\\n\\n### üéß **Audio Overviews (Podcast Feature)**\\n- Generates engaging podcast-style conversations about your documents\\n- Two AI hosts discuss and explain your content in natural dialogue\\n- Great for consuming complex information in audio format\\n\\n### ‚ùì **Interactive Q&A**\\n- Ask specific questions about your uploaded documents\\n- Get precise answers with citations to source material\\n- Helps you dig deeper into complex topics\\n\\n### üìö **Study Guide Creation**\\n- Automatically generates study guides from your materials\\n- Creates summaries, key points, and practice questions\\n- Organizes information for better learning retention\\n\\n## Benefits for Research\\n\\n### ‚úÖ **Advantages:**\\n- **Source-Specific**: Only uses your uploaded documents (no hallucination from external sources)\\n- **Citation Support**: Provides references to specific parts of your documents\\n- **Multiple Formats**: Handles various document types seamlessly\\n- **Audio Learning**: Convert dense text into digestible audio content\\n- **Time-Saving**: Quickly summarize lengthy documents\\n- **Interactive Exploration**: Ask follow-up questions to dive deeper\\n\\n## Limitations\\n\\n### ‚ö†Ô∏è **Current Constraints:**\\n- **Document Limit**: Limited number of sources per notebook\\n- **File Size Restrictions**: May have upload size limitations\\n- **Language Support**: Primarily optimized for English content\\n- **Mobile Limitations**: Some features may be restricted on mobile app\\n- **Experimental Status**: Still in development, features may change\\n- **No Real-Time Data**: Can\\'t access current web information beyond uploaded docs\\n\\n## Research Workflow Tips & Tricks\\n\\n### üîç **Getting Started:**\\n1. **Organize by Project**: Create separate notebooks for different research topics\\n2. **Upload Strategically**: Start with your most important/comprehensive sources\\n3. **Use Descriptive Names**: Name your sources clearly for easy reference\\n\\n### üí° **Query Optimization:**\\n- **Be Specific**: Ask clear, focused questions rather than vague ones\\n- **Use Follow-ups**: Build on previous answers with more detailed questions\\n- **Request Citations**: Ask for specific page numbers or sections for verification\\n- **Try Different Angles**: Approach the same topic from multiple perspectives\\n\\n### üéØ **Advanced Techniques:**\\n- **Comparative Analysis**: Upload multiple sources and ask NotebookLM to compare viewpoints\\n- **Summary Hierarchies**: Request executive summaries, then detailed breakdowns\\n- **Question Generation**: Ask it to generate research questions based on your documents\\n- **Gap Identification**: Have it identify areas that need more research\\n\\n### üéß **Audio Overview Best Practices:**\\n- Generate audio overviews for complex topics you want to review while commuting\\n- Use them as a \"first pass\" to understand document structure before deep reading\\n- Great for team briefings - share audio summaries with colleagues\\n\\n### üìù **Study Guide Optimization:**\\n- Upload lecture notes, textbooks, and supplementary materials together\\n- Request different types of study materials (flashcards, practice questions, concept maps)\\n- Use iterative refinement - ask for more details on specific sections\\n\\n## Best Use Cases\\n\\n- **Academic Research**: Literature reviews, thesis preparation, coursework\\n- **Professional Analysis**: Market research, competitive analysis, policy review\\n- **Learning & Education**: Course materials, certification prep, skill development\\n- **Content Creation**: Research for articles, presentations, or reports\\n- **Legal/Medical Review**: Case studies, research papers, documentation analysis\\n\\nNotebookLM excels when you have substantial source material and need to extract insights, create learning materials, or conduct deep analysis. It\\'s particularly powerful for researchers who work with multiple complex documents and need an AI assistant that stays grounded in their specific content.', 'type': 'text'}], additional_kwargs={}, response_metadata={'id': 'msg_017bS4ZuQnowqCTpgJhiYDDP', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 2287, 'output_tokens': 1027, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--3c80285f-dd29-4497-8112-0b529b438e8a-0', usage_metadata={'input_tokens': 2287, 'output_tokens': 1027, 'total_tokens': 3314, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Message 3] You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üëã Ending chat session. Goodbye!\n",
      "\n",
      "Script finished. Total messages processed: 2\n",
      "\n",
      "üìä Session Summary:\n",
      "   - Thread ID: interactive-thread-b4abe117\n",
      "   - Messages processed: 2\n",
      "   - Session ended gracefully\n"
     ]
    }
   ],
   "source": [
    "# Interactive Chat Loop for Jupyter Notebook\n",
    "\n",
    "print(\"Starting Agentic LangGraph Script...\")\n",
    "print(\"ü§ñ Interactive Chat Session\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Commands:\")\n",
    "print(\"- Type your message to chat with the agent\")\n",
    "print(\"- Type 'quit', 'exit', or 'bye' to end the session\")\n",
    "print(\"- Type 'clear' to start a new conversation thread\")\n",
    "print(\"- Type 'help' to see these commands again\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize thread ID\n",
    "thread_id = f\"interactive-thread-{str(uuid.uuid4())[:8]}\"\n",
    "message_count = 0\n",
    "\n",
    "# Main chat loop\n",
    "while True:\n",
    "    try:\n",
    "        # Get user input\n",
    "        user_input = input(f\"\\n[Message {message_count + 1}] You: \").strip()\n",
    "        \n",
    "        # Handle empty input\n",
    "        if not user_input:\n",
    "            print(\"Please enter a message or 'quit' to exit.\")\n",
    "            continue\n",
    "        \n",
    "        # Handle exit commands\n",
    "        if user_input.lower() in ['quit', 'exit', 'bye', 'q']:\n",
    "            print(\"\\nüëã Ending chat session. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Handle clear command\n",
    "        elif user_input.lower() == 'clear':\n",
    "            thread_id = f\"interactive-thread-{str(uuid.uuid4())[:8]}\"\n",
    "            message_count = 0\n",
    "            print(f\"üîÑ Started new conversation thread: {thread_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Handle help command\n",
    "        elif user_input.lower() == 'help':\n",
    "            print(\"\\nCommands:\")\n",
    "            print(\"- Type your message to chat with the agent\")\n",
    "            print(\"- Type 'quit', 'exit', or 'bye' to end the session\")\n",
    "            print(\"- Type 'clear' to start a new conversation thread\")\n",
    "            print(\"- Type 'help' to see these commands again\")\n",
    "            continue\n",
    "        \n",
    "        # Process the user input with the agent\n",
    "        print(f\"\\nüîÑ Processing... (Thread: {thread_id})\")\n",
    "        stream_memory_responses(user_input, thread_id)\n",
    "        message_count += 1\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è Chat session interrupted by user (Ctrl+C)\")\n",
    "        break\n",
    "    except EOFError:\n",
    "        print(\"\\n\\n‚ö†Ô∏è Input stream ended\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error occurred: {e}\")\n",
    "        print(\"Continuing chat session...\")\n",
    "\n",
    "print(f\"\\nScript finished. Total messages processed: {message_count}\")\n",
    "\n",
    "# Optional: Display conversation statistics\n",
    "print(f\"\\nüìä Session Summary:\")\n",
    "print(f\"   - Thread ID: {thread_id}\")\n",
    "print(f\"   - Messages processed: {message_count}\")\n",
    "print(f\"   - Session ended gracefully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583c615-6b0e-4136-8f3a-26c1ccd9e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yeah, so I'm loooking for some info on NotebookLM- specifically what is it? benefits / limitations and how it can help me conduct research. provide an overview of the product with some useful tips & tricks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
