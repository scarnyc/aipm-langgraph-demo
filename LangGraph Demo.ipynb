{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a473efc-098c-46ad-b282-93c109d52378",
   "metadata": {},
   "source": [
    "# LangGraph Demo\n",
    "## 3 Agents 👇\n",
    "* ReAct Agent built with LangGraph + Claude + Taviily Web Search + Wikipedia Search & Summarization\n",
    "* Agentic Workflow that has access to the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a425b6c-b866-4c03-98d4-103bfe0babef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import environment file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# text structure\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Union, Callable\n",
    "from pydantic import BaseModel, Field\n",
    "from urllib.parse import quote\n",
    "\n",
    "# datetime\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "# LangGraph graph def\n",
    "from langgraph.graph import MessagesState, START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# Messages\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Claude & OpenAI integration\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# creating ReAct agents with Supervisor architecture\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Define Tavily Search + Wiki Tools\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools.tavily_search.tool import TavilySearchResults\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# jupyter finessing\n",
    "from IPython.display import Image, display, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# gradio\n",
    "import gradio as gr\n",
    "\n",
    "# needed for concurrent evals in notebook envs\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6120a-8a48-4c83-b644-53c10bbb412c",
   "metadata": {},
   "source": [
    "# ReAct Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07029e-141c-45da-aeff-a94520723801",
   "metadata": {},
   "source": [
    "## Model Initialization 🎈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1215b67c-c2b6-4cdc-8ade-cd28d36170f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "if not anthropic_api_key:\n",
    "    print(\"ANTHROPIC_API_KEY environment variable not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f053e8-ccc9-4201-9f02-4f7a7cf69e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'claude-sonnet-4-20250514'\n",
    "# 'claude-4-sonnet-20250514'\n",
    "# 'claude-opus-4-20250514'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca12520-4548-4c9c-aef0-41182c8b42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ChatAnthropic(\n",
    "    model_name=MODEL,\n",
    "    temperature=1,\n",
    "    max_tokens=2000,\n",
    "    \n",
    "    # Enable thinking with budget_tokens as required by API  \n",
    "    thinking={\"type\": \"enabled\", \"budget_tokens\": 1024},\n",
    "    \n",
    "    # Enable interleaved thinking for better tool use and reasoning\n",
    "    extra_headers={\n",
    "        \"anthropic-beta\": \"interleaved-thinking-2025-05-14\"\n",
    "    },\n",
    "    \n",
    "    # Enable keep-alive as recommended by Anthropic\n",
    "    timeout=300.0,  # 5 minute timeout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f2c1e-a3e1-4a88-81b3-6a87ffa8627d",
   "metadata": {},
   "source": [
    "## Define Tools ⚙️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f57df-4a27-43ae-9b91-161ac109fc6b",
   "metadata": {},
   "source": [
    "### 1️⃣ Tavily Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb60771b-a235-45ef-99fe-c1eb229d8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "if not tavily_api_key:\n",
    "    print(\"TAVILY_API_KEY environment variable not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabfcef4-9f0f-491e-a98c-c74a434e8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tavily_search_tool(tavily_api_key):\n",
    "    \"\"\"\n",
    "    Create the Tavily search tool with token management.\n",
    "    \n",
    "    Args:\n",
    "        tavily_api_key: API key for Tavily\n",
    "    Returns:\n",
    "        Configured search tool or None if failed\n",
    "\n",
    "     Use this tool when:\n",
    "    - User asks questions that require current info\n",
    "    \"\"\"\n",
    "    try:\n",
    "        def tavily_search(query, *args, **kwargs):\n",
    "            \n",
    "            try:\n",
    "                print(f\"Making Tavily API call for: {query[:50]}...\")\n",
    "                results = TavilySearchResults(api_key=tavily_api_key,\n",
    "                                             # k=1,\n",
    "                                             include_raw_content=False,\n",
    "                                             include_images=False,\n",
    "                                             include_answer=True,\n",
    "                                             max_results=1,\n",
    "                                             search_depth=\"basic\")(query, *args, **kwargs)\n",
    "                \n",
    "                return results\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in Tavily search: {e}\")\n",
    "                \n",
    "                return error_result\n",
    "\n",
    "        search_tool = Tool(\n",
    "            name=\"tavily_search_results\",\n",
    "            func=tavily_search,\n",
    "            description=\n",
    "            \"Search the web for current information. Useful for questions about current events or trending topics.\"\n",
    "        )\n",
    "\n",
    "        print(\"Successfully initialized Tavily Search with token management\")\n",
    "        return search_tool\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize Tavily Search: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6615f1-cb92-4224-bb1c-9b41005fddad",
   "metadata": {},
   "source": [
    "### 2️⃣ DateTime Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b9075fe-e531-4eb3-8835-eca0e0ddc9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"\n",
    "    Get the current date and time in a user-friendly format.\n",
    "    \n",
    "    Returns:\n",
    "        str: Current date and time in format \"Friday, May 23, 2025 at 12:45 PM EST\"\n",
    "    \n",
    "    Use this tool when:\n",
    "    - User asks about current date, time, or \"today\"\n",
    "    - User mentions \"this week\", \"next week\", \"this month\", etc.\n",
    "    - User asks about weather forecasts or current events\n",
    "    - Any time-sensitive queries that need current context\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get current datetime in UTC\n",
    "        now_utc = datetime.now(timezone.utc)\n",
    "        \n",
    "        # Format for user display\n",
    "        formatted_date = now_utc.strftime(\"%A, %B %d, %Y at %I:%M %p UTC\")\n",
    "        \n",
    "        return f\"Current date and time: {formatted_date}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error getting current datetime: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91f551-5be8-4c7a-9d5c-7f8060d6c4f1",
   "metadata": {},
   "source": [
    "### 3️⃣ Wiki Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf7849c-ba19-4491-b887-ef8a1161d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wikipedia_tool():\n",
    "    \"\"\"\n",
    "    Create a Wikipedia search tool.\n",
    "\n",
    "    Returns:\n",
    "        Configured Wikipedia tool or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        api_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=3000)\n",
    "\n",
    "        # Wrap the Wikipedia run to provide error handling, token management, and caching\n",
    "        def wiki_query_with_handling(query):\n",
    "            # Input validation\n",
    "            if not query or not isinstance(query, str):\n",
    "                return \"Invalid query: Please provide a valid search term.\"\n",
    "            \n",
    "            # Sanitize query - remove potentially problematic characters\n",
    "            query = query.strip()\n",
    "            if len(query) > 300:  # Align with WIKIPEDIA_MAX_QUERY_LENGTH\n",
    "                query = query[:300]\n",
    "            \n",
    "            try:\n",
    "                print(f\"Making Wikipedia API call for: {query[:50]}...\")\n",
    "                result = api_wrapper.run(query)\n",
    "\n",
    "                # Limit result size to avoid token issues\n",
    "                if len(result) > 4000:\n",
    "                    result = result[:4000] + \"... [content truncated for brevity]\"\n",
    "\n",
    "                # Add Wikipedia source URL with proper encoding\n",
    "                wiki_title = quote(query.replace(' ', '_'), safe='')\n",
    "                wiki_url = f\"https://en.wikipedia.org/wiki/{wiki_title}\"\n",
    "                result += f\"\\n\\nSources:\\n{wiki_url}\"\n",
    "\n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_result = \"Wikipedia search encountered an error. Please try a different query or check your connection.\"\n",
    "                print(f\"Error in Wikipedia search: {e}\")\n",
    "                \n",
    "                return error_result\n",
    "\n",
    "        # Create the tool with our wrapped function\n",
    "        wiki_tool = Tool(\n",
    "            name=\"wikipedia_query_run\",\n",
    "            func=wiki_query_with_handling,\n",
    "            description=\"\"\"Searches Wikipedia for information about a given topic. \n",
    "            Use for historical, scientific, or general knowledge queries.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        print(\"Successfully initialized Wikipedia tool\")\n",
    "        return wiki_tool\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize Wikipedia tool: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849c946-aef6-49a7-b65e-5250ebe7994a",
   "metadata": {},
   "source": [
    "### Prompt Template 📝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad8ab702-6902-4134-8850-04809eb068de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt():\n",
    "    \"\"\"\n",
    "    Returns an enhanced prompt for the ReACT agent that coordinates between multiple tools.\n",
    "    Include special instructions for handling content.\n",
    "    \"\"\"\n",
    "    return \"\"\"\n",
    "    You are an expert AI assistant with access to powerful tools for research and information gathering.\n",
    "\n",
    "    CAPABILITIES:\n",
    "    - Web search via Tavily (for current events, news, real-time information)\n",
    "    - Wikipedia search (for encyclopedic knowledge, historical facts, established concepts)\n",
    "    - Current date/time information\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. **Tool Selection Strategy**:\n",
    "       - Use Tavily search for: recent events, current facts, market data, news, trending topics\n",
    "       - Use Wikipedia for: historical information, established concepts, biographical data, scientific facts\n",
    "       - Get current datetime before searching when queries involve time-sensitive information\n",
    "    \n",
    "    2. **Response Guidelines**:\n",
    "       - Always provide direct, helpful answers based on your research\n",
    "       - Synthesize information from multiple sources when appropriate\n",
    "       - If you need to search for information, explain briefly what you're looking for\n",
    "       - Cite sources when presenting factual claims from your searches\n",
    "       - Be concise but thorough in your explanations\n",
    "    \n",
    "    3. **Search Strategy**:\n",
    "       - For time-sensitive queries (weather, recent events), always get current date first\n",
    "       - Use multiple searches if needed to provide comprehensive answers\n",
    "       - Prefer authoritative sources and recent information\n",
    "    \n",
    "    4. **Communication Style**:\n",
    "       - Be helpful, accurate, and conversational\n",
    "       - Acknowledge when you're searching for information\n",
    "       - Present information clearly and organize complex topics logically\n",
    "    \n",
    "    Current date context will be provided when you use the datetime tool.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a157d08f-b644-440f-b024-cecc291b3c99",
   "metadata": {},
   "source": [
    "## Initialize Tools ✅ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2738ee8-0b42-467e-a9fe-ad592d9be155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized Tavily Search with token management\n",
      "✅ Tavily search tool initialized\n",
      "Successfully initialized Wikipedia tool\n",
      "✅ Wikipedia tool initialized\n",
      "✅ DateTime tool initialized\n",
      "\n",
      "🎯 Agent created with 3 tools:\n",
      "   - tavily_search_results\n",
      "   - wikipedia_query_run\n",
      "   - get_current_datetime\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize the tools properly by calling the factory functions\n",
    "def initialize_tools():\n",
    "    \"\"\"Initialize all tools and return them as a list\"\"\"\n",
    "    tools = []\n",
    "    \n",
    "    # Initialize Tavily search tool\n",
    "    if tavily_api_key:\n",
    "        tavily_tool = create_tavily_search_tool(tavily_api_key)\n",
    "        if tavily_tool:\n",
    "            tools.append(tavily_tool)\n",
    "            print(\"✅ Tavily search tool initialized\")\n",
    "        else:\n",
    "            print(\"❌ Failed to initialize Tavily search tool\")\n",
    "    else:\n",
    "        print(\"⚠️ Tavily API key not found, skipping Tavily tool\")\n",
    "    \n",
    "    # Initialize Wikipedia tool\n",
    "    wiki_tool = create_wikipedia_tool()\n",
    "    if wiki_tool:\n",
    "        tools.append(wiki_tool)\n",
    "        print(\"✅ Wikipedia tool initialized\")\n",
    "    else:\n",
    "        print(\"❌ Failed to initialize Wikipedia tool\")\n",
    "    \n",
    "    # Add datetime tool\n",
    "    tools.append(get_current_datetime)\n",
    "    print(\"✅ DateTime tool initialized\")\n",
    "    \n",
    "    return tools\n",
    "\n",
    "# 3. Initialize tools\n",
    "available_tools = initialize_tools()\n",
    "\n",
    "print(f\"\\n🎯 Agent created with {len(available_tools)} tools:\")\n",
    "for tool in available_tools:\n",
    "    if hasattr(tool, 'name'):\n",
    "        print(f\"   - {tool.name}\")\n",
    "    else:\n",
    "        print(f\"   - {tool}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d090d-42bd-4b64-adce-6f3b3197604f",
   "metadata": {},
   "source": [
    "## Create First ReAct Agent 🤖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0677114b-9935-4b6e-9ada-69a436ecbfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_one = create_react_agent(\n",
    "    model=claude,\n",
    "    tools=available_tools,\n",
    "    name=\"expert_sme\",\n",
    "    prompt=get_prompt(),\n",
    "\n",
    "    # add Memory\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913f7e37-65d5-4376-94a5-5f438e25ed38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(agent_one.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7406a6-0c4c-41f9-b6be-01c005637b24",
   "metadata": {},
   "source": [
    "## ❓Questions with Multiple Tool Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "599771ca-d483-42d5-9ff1-4acb1430c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_agent_trace(query):\n",
    "    \"\"\"\n",
    "    Break down user / agent interaction trace into streams for surface-level observability.\n",
    "    \"\"\"\n",
    "    _thread_counter = 0\n",
    "    \n",
    "    # Get tracer (ensure Phoenix is set up first)\n",
    "    # tracer = trace.get_tracer(__name__)\n",
    "    \n",
    "    # Auto-increment thread_id\n",
    "    _thread_counter += 1\n",
    "    thread_id = f\"thread_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{_thread_counter}\"\n",
    "\n",
    "    # Define config with thread_id\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id\n",
    "        },\n",
    "        \"recursion_limit\": 50,\n",
    "        \"max_execution_time\": 300,  # 5 min timeout\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n🤔 USER QUERY: {query}\")\n",
    "    print(f\"🔗 Thread ID: {thread_id}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    step_counter = 1\n",
    "    reasoning_parts = []\n",
    "    \n",
    "    for msg, metadata in agent_one.stream(\n",
    "        {\"messages\": [HumanMessage(content=query)]}, \n",
    "        config, \n",
    "        stream_mode=\"messages\"\n",
    "    ):\n",
    "        # safely extract message type\n",
    "        msg_type = getattr(msg, 'type', None) \n",
    "        \n",
    "        # Handle HumanMessage (user input)\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            continue  # Skip user messages in trace\n",
    "        \n",
    "        # Handle AIMessage (assistant responses)\n",
    "        elif hasattr(msg, 'content') and msg.content:\n",
    "            \n",
    "            if isinstance(msg.content, list):\n",
    "                for block in msg.content:\n",
    "                    if isinstance(block, dict):\n",
    "                        block_type = block.get('type', '')\n",
    "                        \n",
    "                        # Reasoning/Thinking\n",
    "                        if block_type == 'thinking':\n",
    "                            reasoning_parts.append(block.get('thinking', ''))\n",
    "                        \n",
    "                        # Agent speech/explanation\n",
    "                        elif block_type == 'text':\n",
    "                            # Show accumulated reasoning first\n",
    "                            if reasoning_parts:\n",
    "                                reasoning_text = ''.join(reasoning_parts).strip()\n",
    "                                if reasoning_text:\n",
    "                                    print(f\"\\n🧠 STEP {step_counter} - AGENT REASONING:\")\n",
    "                                    print(f\"   {reasoning_text}\")\n",
    "                                    reasoning_parts = []\n",
    "                                    step_counter += 1\n",
    "                            \n",
    "                            text_content = block.get('text', '').strip()\n",
    "                            if text_content:\n",
    "                                print(f\"\\n🤖 ASSISTANT RESPONSE:\")\n",
    "                                print(f\"   {text_content}\")\n",
    "                        \n",
    "                        # Tool usage\n",
    "                        elif block_type == 'tool_use':\n",
    "                            tool_name = block.get('name', '')\n",
    "                            tool_input = block.get('input', {})\n",
    "                            \n",
    "                            print(f\"\\n🔧 TOOL CALL:\")\n",
    "                            print(f\"   Using: {tool_name}\")\n",
    "                            if tool_input:\n",
    "                                print(f\"   Parameters: {tool_input}\")\n",
    "            \n",
    "            # Handle direct string responses\n",
    "            elif isinstance(msg.content, str):\n",
    "                content = msg.content.strip()\n",
    "                if content:\n",
    "                    print(f\"\\n🤖 ASSISTANT:\")\n",
    "                    print(f\"   {content}\")\n",
    "        \n",
    "        # Handle ToolMessage (tool results)\n",
    "        elif msg_type == 'tool':\n",
    "            print(f\"\\n📊 TOOL RESULT:\")\n",
    "            content = getattr(msg, 'content', '')\n",
    "            # Truncate long tool results for readability\n",
    "            if len(content) > 300:\n",
    "                print(f\"   {content[:300]}...\")\n",
    "            else:\n",
    "                print(f\"   {content}\")\n",
    "    \n",
    "    # Show any final reasoning\n",
    "    if reasoning_parts:\n",
    "        reasoning_text = ''.join(reasoning_parts).strip()\n",
    "        if reasoning_text:\n",
    "            print(f\"\\n🧠 FINAL REASONING:\")\n",
    "            print(f\"   {reasoning_text}\")\n",
    "    \n",
    "    print(f\"\\n✅ QUERY COMPLETED\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345a1ae2-1ffa-4f74-9e1f-239fb09323dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"what's the weather like in Queens today?\", \n",
    "    \"Who was the King of the Ancient Greek Gods?\",\n",
    "    \"What's the best method to evaluate an LLM?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8773a7fd-55f3-4b27-9ead-ca1ca314f4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "🤔 USER QUERY: what's the weather like in Queens today?\n",
      "🔗 Thread ID: thread_20250910_210516_1\n",
      "================================================================================\n",
      "\n",
      "🧠 STEP 1 - AGENT REASONING:\n",
      "   The user is asking about today's weather in Queens. This is a time-sensitive query that requires current information, so I should:\n",
      "\n",
      "1. First get the current date/time to know what \"today\" refers to\n",
      "2. Then search for current weather information in Queens using Tavily search\n",
      "\n",
      "Let me start with getting the current datetime.\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   I'll help you find the current weather in Queens.\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   Let me first get today's date and then\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   search for the latest weather information.\n",
      "\n",
      "🔧 TOOL CALL:\n",
      "   Using: get_current_datetime\n",
      "\n",
      "🤖 ASSISTANT:\n",
      "   Current date and time: Thursday, September 11, 2025 at 01:05 AM UTC\n",
      "\n",
      "🔧 TOOL CALL:\n",
      "   Using: tavily_search_results\n",
      "Making Tavily API call for: current weather Queens New York today September 11...\n",
      "\n",
      "🤖 ASSISTANT:\n",
      "   [{\"title\": \"Weather in Queens, New York\", \"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'Queens Village', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7267, 'lon': -73.7419, 'tz_id': 'America/New_York', 'localtime_epoch': 1757552753, 'localtime': '2025-09-10 21:05'}, 'current': {'last_updated_epoch': 1757552400, 'last_updated': '2025-09-10 21:00', 'temp_c': 21.7, 'temp_f': 71.1, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 4.7, 'wind_kph': 7.6, 'wind_degree': 28, 'wind_dir': 'NNE', 'pressure_mb': 1019.0, 'pressure_in': 30.09, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 55, 'cloud': 75, 'feelslike_c': 21.7, 'feelslike_f': 71.1, 'windchill_c': 18.5, 'windchill_f': 65.4, 'heatindex_c': 18.5, 'heatindex_f': 65.4, 'dewpoint_c': 13.5, 'dewpoint_f': 56.3, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 7.3, 'gust_kph': 11.7}}\", \"score\": 0.9536964}]\n",
      "\n",
      "🧠 STEP 2 - AGENT REASONING:\n",
      "   Now I have the current date - it's Thursday, September 11, 2025. Let me search for current weather information in Queens, NY.Perfect! I got current weather data for Queens, NY. The data shows it's currently evening time (9:05 PM local time on September 10th, which makes sense since it's early morning UTC on September 11th). Let me provide a clear summary of the current weather conditions.\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   Based on the latest weather data for\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   Queens, New York (\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   as of September 10th\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   , 9:00\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   PM local time):\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   **Current Weather in Queens:**\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   - **Temperature:**\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   71.\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   1°F (21.7°\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   C) - feels like 71°F\n",
      "- **\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   Conditions:** Partly cloudy (\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   75% cloud cover)\n",
      "- **Wind:** Light\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   winds at 4.7 mph from\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   the north-northeast\n",
      "- **Humidity:**\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   55%\n",
      "- **Visibility\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   :** 9 miles\n",
      "- **Pressure:** 30\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   .09 inches\n",
      "- **No precipitation**\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   It's a pleasant evening in\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   Queens with mil\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   d temperatures and partly cloudy skies. The weather\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   conditions are quite comfortable with\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   light winds and moderate humidity levels.\n",
      "\n",
      "For\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   the most up-to-date hour\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   ly forecast and any weather alerts\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   , I'd recommend checking your local weather service\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   , as conditions can change throughout\n",
      "\n",
      "🤖 ASSISTANT RESPONSE:\n",
      "   the day.\n",
      "\n",
      "✅ QUERY COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "user_agent_trace(queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbbb9f0-31cf-4c06-a18d-b3376041cea6",
   "metadata": {},
   "source": [
    "# Workflow Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f732d01-9317-4e53-8ddc-4f83a67ef897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ToolNode to handle LangChain tool calls\n",
    "tool_node = ToolNode(available_tools)\n",
    "\n",
    "# Bind the custom LangChain tools to the LLM\n",
    "model_with_tools = claude.bind_tools(available_tools)\n",
    "\n",
    "# # Define workflow functions\n",
    "\n",
    "# ## Create a stopping function\n",
    "# Use MessagesState to define the state of the stopping function\n",
    "def should_continue(state: MessagesState) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether the agent should continue processing or end.\n",
    "    Args:\n",
    "        state: The current state of the graph, containing messages.\n",
    "    Returns:\n",
    "        \"tools\" if the last message contains tool calls, END otherwise.\n",
    "    \"\"\"\n",
    "    # Get the last message from the state\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # Check if the last message is an AIMessage and has tool_calls\n",
    "    # LangChain tools bound with .bind_tools() appear in `tool_calls`\n",
    "    # Adjust this logic if necessary based on how built-in tool calls are represented.\n",
    "    if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "         # Check specifically for LangChain tool calls\n",
    "        if any(tc.get('name') in [t.name for t in available_tools] for tc in last_message.tool_calls):\n",
    "             return \"tools\" # Route to the LangChain tool node\n",
    "\n",
    "    # Check for Google built-in tool calls (heuristic, might need adjustment)\n",
    "    if isinstance(last_message, AIMessage) and last_message.additional_kwargs.get(\"tool_calls\"):\n",
    "         # The model might handle these directly without needing an explicit \"tools\" step in the graph\n",
    "         # If the model *responds* with content after using a built-in tool, we might want to end.\n",
    "         # If it needs explicit execution confirmation/results, the graph needs adjustment.\n",
    "         # For now, assume the model handles built-in tools and we end if no *LangChain* tools are called.\n",
    "         pass # Let the flow continue to END if no LangChain tools were called\n",
    "\n",
    "    # End the conversation if no explicit LangChain tool calls are present\n",
    "    return END\n",
    "\n",
    "\n",
    "## Create the system prompt \n",
    "def create_agent_prompt():\n",
    "    \"\"\"\n",
    "    Creates a comprehensive prompt template for the workflow agent.\n",
    "    \"\"\"\n",
    "    system_template = get_prompt()\n",
    "\n",
    "    # Create the full prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_template),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ])\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def call_model_with_prompt(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Enhanced agent node function that uses a prompt template.\n",
    "    Args:\n",
    "        state: The current state of the graph.\n",
    "    Returns:\n",
    "        A dictionary containing the updated messages list.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Get the prompt template\n",
    "    prompt_template = create_agent_prompt()\n",
    "    \n",
    "    # Format the prompt with current messages\n",
    "    # This creates a properly formatted conversation with system instructions\n",
    "    formatted_messages = prompt_template.format_messages(messages=messages)\n",
    "    \n",
    "    # Invoke the model with the formatted prompt\n",
    "    response = model_with_tools.invoke(formatted_messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "    \n",
    "## Create a dynamic tool caller (Agent Node)\n",
    "def call_model(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    The main agent node function. Invokes the LLM.\n",
    "    Args:\n",
    "        state: The current state of the graph.\n",
    "    Returns:\n",
    "        A dictionary containing the updated messages list.\n",
    "    \"\"\"\n",
    "    # Note: The original function had logic to handle tool responses directly.\n",
    "    # In a typical LangGraph setup, the ToolNode handles executing tools\n",
    "    # and adding ToolMessages back to the state. This node should primarily\n",
    "    # focus on calling the LLM with the current state.\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    # The response from the LLM (which might include content and/or tool calls)\n",
    "    # is added back to the state.\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c024f2fc-ac69-424e-a338-d628ee910804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes for chatbot (agent) and LangChain tools\n",
    "workflow.add_node(\"chatbot\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node) # Node to execute LangChain tools\n",
    "\n",
    "# Connect the START node to the chatbot\n",
    "workflow.set_entry_point(\"chatbot\")\n",
    "\n",
    "# Define conditional edges:\n",
    "# After chatbot node, check if we should continue (call tools) or end.\n",
    "workflow.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\", # If should_continue returns \"tools\", go to the tools node\n",
    "        END: END          # If should_continue returns END, finish the graph\n",
    "    }\n",
    ")\n",
    "\n",
    "# After the tools node executes tools, always go back to the chatbot node\n",
    "# The ToolNode adds ToolMessages, and the chatbot node will process them.\n",
    "workflow.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Adding memory\n",
    "# Set up memory and compile the workflow\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f9f926-f480-4f1e-abfa-9991e7a9ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Organize chatbot outputs with memory\n",
    "# ## Streaming outputs with memory (Alternative Streaming Approach)\n",
    "\n",
    "# Set up a streaming function for a single user session\n",
    "def stream_memory_responses(user_input: str, thread_id: str):\n",
    "    \"\"\"\n",
    "    Streams all events from the graph execution for a single input.\n",
    "    Args:\n",
    "        user_input: The user's input string.\n",
    "        thread_id: The unique identifier for the conversation thread.\n",
    "    \"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    print(f\"\\n--- Streaming Events (Thread: {thread_id}, Input: '{user_input}') ---\")\n",
    "\n",
    "    # Stream the events in the graph\n",
    "    for event in app.stream({\"messages\": [(\"user\", user_input)]}, config):\n",
    "\n",
    "        # Return the agent's last response\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and value[\"messages\"]:\n",
    "                print(\"Agent:\", value[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f57f6a9-d767-4e65-bb23-3d932419aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Agentic LangGraph Script...\n",
      "\n",
      "--- Streaming Events (Thread: thread-example-3-stream, Input: 'What is the Parthenon?') ---\n",
      "Agent: [AIMessage(content=[{'signature': 'EsEDCkYIBxgCKkAPlXsFQ0EhSSovLbj3skYinR9GzvXglom3o0C/proH27ow+sQInffFmSUiOQzSwENCLNLk0egOwKsQIpXBwEhjEgx9m+2eV3YLKq1Cq/kaDAdisRSHUGVW4mkXriIw986reGXTQQsMJbkFUdH1yqRiBUxIX+eA9l2Uu/72Brt9hOS4gvHgat/4uGH60O13KqgC7suaPQ2+qkRSQx2Qhi/dWOzCxKV9OJ4HJzzd3/0HgqyvbZIXcsMOxpcllMWabNbir5A04Nz8s5XKy7IP4vG9vCxi3vIYGeTjW8WLoBhrSU41yHyDfb2v6DZ91ZrRIIG4y6wAHlHlJvo+J0l20W+zRQ0JkfFIZmXDpDZ7aA9S1vVaLJrP0BpUaJqCp6JBlSMOOee7Px3+YKzZY9AHyq7BFvm+w3dc4ZBzLm4n6uIOu63Dt5r3Y03K9SlZkRDwIi3dwLgaZG/80q3jcA20heob/ie/y5LaEzhwUrqn8vGHtGQoq3iwWdrdJ3damrzbbTjSP2+1MfWSL/urgc2hGyLJrYfDkKEcyB0Ck0r7Mymeh9VMj3b4R3blFVfNQhTKU9TnN+m3G6zEh9kYAQ==', 'thinking': \"The user is asking about the Parthenon. This is a well-known historical and architectural structure. I should use the Wikipedia query function to get detailed, accurate information about the Parthenon since it's a historical/cultural topic that would be well covered in Wikipedia.\", 'type': 'thinking'}, {'id': 'toolu_01ANwqb4pUdtbrPJgUoxwowr', 'input': {'__arg1': 'Parthenon'}, 'name': 'wikipedia_query_run', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01PNHLxV5G4QaeL57JfmcHec', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 826, 'output_tokens': 126, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--2deb0d4a-353d-4122-8fb5-9d203c3cc9f5-0', tool_calls=[{'name': 'wikipedia_query_run', 'args': {'__arg1': 'Parthenon'}, 'id': 'toolu_01ANwqb4pUdtbrPJgUoxwowr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 826, 'output_tokens': 126, 'total_tokens': 952, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n",
      "Making Wikipedia API call for: Parthenon...\n",
      "Agent: [ToolMessage(content=\"Page: Parthenon\\nSummary: The Parthenon (; Ancient Greek: Παρθενών, romanized: Parthenōn [par.tʰe.nɔ̌ːn]; Greek: Παρθενώνας, romanized: Parthenónas [parθeˈnonas]) is a former temple on the Athenian Acropolis, Greece, that was dedicated to the goddess Athena. Its decorative sculptures are considered some of the high points of classical Greek art, and the Parthenon is considered an enduring symbol of ancient Greece, democracy, and Western civilization. \\nThe Parthenon was built in the 5th century BC in thanksgiving for the Greek victory over the Persian invaders during the Greco-Persian Wars. Like most Greek temples, the Parthenon also served as the city treasury. Construction started in 447 BC when the Delian League was at the peak of its power. It was completed in 438 BC; work on the artwork and decorations continued until 432 BC. For a time, it served as the treasury of the Delian League, which later became the Athenian Empire.\\nIn the final decade of the 6th century AD, the Parthenon was converted into a Christian church dedicated to the Virgin Mary. After the Ottoman conquest in the mid-15th century, it became a mosque. In the Morean War, a Venetian bomb landed on the Parthenon, which the Ottomans had used as a munitions dump, during the 1687 siege of the Acropolis. The resulting explosion severely damaged the Parthenon. From 1800 to 1803, the 7th Earl of Elgin controversially removed many of the surviving sculptures and subsequently shipped them to England where they are now known as the Elgin Marbles or Parthenon marbles. Since 1975, numerous large-scale restoration projects have been undertaken to preserve remaining artefacts and ensure its structural integrity.\\n\\n\\n\\nPage: Parthenon (Nashville)\\nSummary: The Parthenon in Centennial Park, Nashville, Tennessee, United States, is a full-scale replica of the original Parthenon in Athens, Greece. It was designed by architect William Crawford Smith and built in 1897 as part of the Tennessee Centennial Exposition.\\nToday, the Parthenon, which functions as an art museum, stands as the centerpiece of Centennial Park, a public park just west of downtown Nashville. Alan LeQuire's 1990 re-creation of the Athena Parthenos statue in the naos (the east room of the main hall) is the focus of the Parthenon just as it was in ancient Greece. Since the building is complete and its decorations were polychromed (painted in colors) as close to the presumed original as possible, this replica of the original Parthenon in Athens serves as a monument to what is considered the pinnacle of classical architecture. The plaster replicas of the Parthenon Marbles found in the Treasury Room (the west room of the main hall) are direct casts of the original sculptures which adorned the pediments of the Athenian Parthenon, dating to 438 BC. The surviving originals are housed in the British Museum in London and at the Acropolis Museum in Athens.\\n\\n\\n\\nSources:\\nhttps://en.wikipedia.org/wiki/Parthenon\", name='wikipedia_query_run', id='657ba872-b644-48b4-bbe7-77b4e8490f11', tool_call_id='toolu_01ANwqb4pUdtbrPJgUoxwowr')]\n",
      "Agent: [AIMessage(content=[{'signature': 'EqoECkYIBxgCKkBtS12D20SDfmth+DpCbx1+zu2ORZQ+gujMlR9W5x+bGUldS/v5/ui7Vrg5MkQwKq8cByhEbRrud5j7PA5cqtVLEgyIRjVPMlV9vI9QmoEaDGcMBkI/e0ONGICFViIw7/8vFRqPzeO9UJkau3Fu8HC/yPlKHuOqgz+JBgsjXedqYU0pdNO7LvWeNID5GF8YKpEDlZTx555G6zJPY6eqlGXPhMlStIN6fhQyhgi17G5MRfIZv+Gp/soEcCqax8dgGLeTJx8yEMDPu9Bc+SIvizdYEj+d8FnawwrBXZDYNJb3qW1YSo7jllnW1PB7hn6m8jgLD2B1ijU87Fy4vqT2+/GL1oYb2bumea8EycVXDK7wmOiHwdWsW0TepHEsYPuAhOexscRx74RrPvA40WvddAs9m3dfhm7VtATT1uepnzww3SCI9Bo5GNVdrUy/4ek3Ji9iVGjI8WBlYIYc/xJ7g94vYnIKb+JkI0u4cEeYyetvRqjsy34+dGOBHcNeI7w3NNL0dtiXg117NoGaSjqhSOrrMQiHVs0nLs6i7lNNdNJPGbrI3yRDbdVcEd4VvvVDizEtxmzs7SPHNPz7EYDbxMD0F4qOPF/2NkOGSalBj5CRCy8UoDFfN4XpMeg5tLUdAFR02UYE1oJColsVWBOIRpnh4plCWPggR1OKy9MZdldzouKKJxx7l0OKh1SRVfFPGxf9Fyrl4Xcc5eRAk9VhnYO9sVcYAQ==', 'thinking': \"Great, I got detailed information about the Parthenon from Wikipedia. The results show information about both the original Parthenon in Athens and the replica in Nashville. I should focus on the original since that's likely what the user is asking about, but I can mention the replica as well for completeness.\\n\\nLet me provide a comprehensive answer based on the Wikipedia information.\", 'type': 'thinking'}, {'text': 'The Parthenon is a magnificent ancient Greek temple located on the Athenian Acropolis in Greece. Here are the key details about this iconic structure:\\n\\n## What it is:\\n- A former temple dedicated to the goddess Athena\\n- One of the most important surviving buildings of ancient Greece\\n- Considered an enduring symbol of ancient Greece, democracy, and Western civilization\\n\\n## Historical Background:\\n- **Built**: 5th century BC (construction started in 447 BC, completed in 438 BC)\\n- **Purpose**: Built in thanksgiving for the Greek victory over Persian invaders during the Greco-Persian Wars\\n- **Function**: Served as both a temple and the city treasury, later becoming the treasury of the Delian League (Athenian Empire)\\n\\n## Architectural Significance:\\n- Its decorative sculptures are considered high points of classical Greek art\\n- Represents the pinnacle of classical architecture\\n- The building exemplifies the Doric order of ancient Greek architecture\\n\\n## Later History:\\n- **6th century AD**: Converted into a Christian church dedicated to the Virgin Mary\\n- **Mid-15th century**: Became a mosque under Ottoman rule\\n- **1687**: Severely damaged when a Venetian bomb hit it during the Morean War (the Ottomans had been using it as a munitions dump)\\n- **1800-1803**: Many surviving sculptures were removed by the 7th Earl of Elgin and taken to England (now known as the \"Elgin Marbles\" or \"Parthenon Marbles\")\\n- **Since 1975**: Ongoing large-scale restoration projects to preserve the structure\\n\\nThe Parthenon remains one of the world\\'s most recognizable ancient buildings and continues to be a powerful symbol of the cultural achievements of ancient Greece.', 'type': 'text'}], additional_kwargs={}, response_metadata={'id': 'msg_01GHsx3Ri7kDnhrKwWkSRNAQ', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1740, 'output_tokens': 485, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, id='run--917045ff-c3da-41fb-81d7-84296c352166-0', usage_metadata={'input_tokens': 1740, 'output_tokens': 485, 'total_tokens': 2225, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})]\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Agentic LangGraph Script...\")\n",
    "\n",
    "# --- Example 3: Streaming all graph events ---\n",
    "thread3_id = \"thread-example-3-stream\"\n",
    "stream_memory_responses(\"What is the Parthenon?\", thread3_id)\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86994f-ae73-4e50-9ab9-44602e227072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Agentic LangGraph Script...\n",
      "🤖 Interactive Chat Session\n",
      "==================================================\n",
      "Commands:\n",
      "- Type your message to chat with the agent\n",
      "- Type 'quit', 'exit', or 'bye' to end the session\n",
      "- Type 'clear' to start a new conversation thread\n",
      "- Type 'help' to see these commands again\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Interactive Chat Loop for Jupyter Notebook\n",
    "\n",
    "print(\"Starting Agentic LangGraph Script...\")\n",
    "print(\"🤖 Interactive Chat Session\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Commands:\")\n",
    "print(\"- Type your message to chat with the agent\")\n",
    "print(\"- Type 'quit', 'exit', or 'bye' to end the session\")\n",
    "print(\"- Type 'clear' to start a new conversation thread\")\n",
    "print(\"- Type 'help' to see these commands again\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize thread ID\n",
    "thread_id = f\"interactive-thread-{str(uuid.uuid4())[:8]}\"\n",
    "message_count = 0\n",
    "\n",
    "# Main chat loop\n",
    "while True:\n",
    "    try:\n",
    "        # Get user input\n",
    "        user_input = input(f\"\\n[Message {message_count + 1}] You: \").strip()\n",
    "        \n",
    "        # Handle empty input\n",
    "        if not user_input:\n",
    "            print(\"Please enter a message or 'quit' to exit.\")\n",
    "            continue\n",
    "        \n",
    "        # Handle exit commands\n",
    "        if user_input.lower() in ['quit', 'exit', 'bye', 'q']:\n",
    "            print(\"\\n👋 Ending chat session. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Handle clear command\n",
    "        elif user_input.lower() == 'clear':\n",
    "            thread_id = f\"interactive-thread-{str(uuid.uuid4())[:8]}\"\n",
    "            message_count = 0\n",
    "            print(f\"🔄 Started new conversation thread: {thread_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Handle help command\n",
    "        elif user_input.lower() == 'help':\n",
    "            print(\"\\nCommands:\")\n",
    "            print(\"- Type your message to chat with the agent\")\n",
    "            print(\"- Type 'quit', 'exit', or 'bye' to end the session\")\n",
    "            print(\"- Type 'clear' to start a new conversation thread\")\n",
    "            print(\"- Type 'help' to see these commands again\")\n",
    "            continue\n",
    "        \n",
    "        # Process the user input with the agent\n",
    "        print(f\"\\n🔄 Processing... (Thread: {thread_id})\")\n",
    "        stream_memory_responses(user_input, thread_id)\n",
    "        message_count += 1\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⚠️ Chat session interrupted by user (Ctrl+C)\")\n",
    "        break\n",
    "    except EOFError:\n",
    "        print(\"\\n\\n⚠️ Input stream ended\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error occurred: {e}\")\n",
    "        print(\"Continuing chat session...\")\n",
    "\n",
    "print(f\"\\nScript finished. Total messages processed: {message_count}\")\n",
    "\n",
    "# Optional: Display conversation statistics\n",
    "print(f\"\\n📊 Session Summary:\")\n",
    "print(f\"   - Thread ID: {thread_id}\")\n",
    "print(f\"   - Messages processed: {message_count}\")\n",
    "print(f\"   - Session ended gracefully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583c615-6b0e-4136-8f3a-26c1ccd9e491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
